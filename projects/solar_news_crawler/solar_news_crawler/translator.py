import json
import os
import time
import hashlib
import requests
from datetime import datetime
import glob

def find_latest_file(pattern, directory="output/individual"):
    """æŸ¥æ‰¾æŒ‡å®šæ¨¡å¼çš„æœ€æ–°æ–‡ä»¶"""
    if not os.path.exists(directory):
        return None
    files = glob.glob(os.path.join(directory, pattern))
    if not files:
        return None
    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
    files.sort(key=os.path.getmtime, reverse=True)
    return files[0]

class MultiFileTranslator:
    def __init__(self):
        self.cache_file = 'translation_cache.json'
        self.translation_cache = self._load_cache()
        
    def _load_cache(self):
        """åŠ è½½ç¿»è¯‘ç¼“å­˜"""
        try:
            if os.path.exists(self.cache_file):
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception:
            pass
        return {}
    
    def _save_cache(self):
        """ä¿å­˜ç¿»è¯‘ç¼“å­˜"""
        try:
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.translation_cache, f, ensure_ascii=False, indent=2)
        except Exception:
            pass
    
    def _get_cache_key(self, text):
        """ç”Ÿæˆç¼“å­˜é”®"""
        return hashlib.md5(text.encode('utf-8')).hexdigest()
    
    def translate_text(self, text):
        """ä½¿ç”¨å…è´¹çš„ç¿»è¯‘æœåŠ¡"""
        if not text or not text.strip():
            return text
            
        # æ£€æŸ¥ç¼“å­˜
        cache_key = self._get_cache_key(text)
        if cache_key in self.translation_cache:
            return self.translation_cache[cache_key]
        
        # å°è¯•å¤šä¸ªå…è´¹çš„ç¿»è¯‘æœåŠ¡
        translation_methods = [
            self._libretranslate_translate,
            self._mymemory_translate,
            self._simply_translate
        ]
        
        for method in translation_methods:
            try:
                result = method(text)
                if result and result.strip() and result != text:
                    # ç¼“å­˜ç»“æœ
                    self.translation_cache[cache_key] = result
                    self._save_cache()
                    return result
            except Exception as e:
                print(f"ç¿»è¯‘æ–¹æ³• {method.__name__} å¤±è´¥: {e}")
                continue
        
        return text
    
    def _libretranslate_translate(self, text):
        """ä½¿ç”¨LibreTranslateï¼ˆå¼€æºç¿»è¯‘æœåŠ¡ï¼‰"""
        try:
            # å¤šä¸ªå¯ç”¨çš„LibreTranslateå®ä¾‹
            endpoints = [
                "https://translate.argosopentech.com/translate",
                "https://libretranslate.de/translate",
                "https://translate.fortran.is/translate"
            ]
            
            for endpoint in endpoints:
                try:
                    data = {
                        'q': text,
                        'source': 'en',
                        'target': 'zh',
                        'format': 'text'
                    }
                    
                    response = requests.post(endpoint, json=data, timeout=15)
                    if response.status_code == 200:
                        result = response.json()
                        return result['translatedText']
                except:
                    continue
                    
            return None
        except Exception as e:
            print(f"LibreTranslateå¤±è´¥: {e}")
            return None
    
    def _mymemory_translate(self, text):
        """ä½¿ç”¨MyMemoryç¿»è¯‘APIï¼ˆå…è´¹ï¼‰"""
        try:
            url = "https://api.mymemory.translated.net/get"
            params = {
                'q': text,
                'langpair': 'en|zh'
            }
            
            response = requests.get(url, params=params, timeout=10)
            if response.status_code == 200:
                data = response.json()
                if data.get('responseStatus') == 200:
                    return data['responseData']['translatedText']
        except Exception as e:
            print(f"MyMemoryç¿»è¯‘å¤±è´¥: {e}")
        return None
    
    def _simply_translate(self, text):
        """ä½¿ç”¨SimplyTranslateï¼ˆå¦ä¸€ä¸ªå¼€æºæœåŠ¡ï¼‰"""
        try:
            url = "https://simplytranslate.org/api/translate"
            data = {
                'text': text,
                'from': 'en',
                'to': 'zh'
            }
            
            response = requests.post(url, data=data, timeout=10)
            if response.status_code == 200:
                return response.text.strip()
        except Exception as e:
            print(f"SimplyTranslateå¤±è´¥: {e}")
        return None

    def process_pv_magazine_file(self, filename):
        """å¤„ç†PV Magazineæ ¼å¼çš„æ–‡ä»¶"""
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            print(f"å¤„ç†PV Magazineæ–‡ä»¶: {filename}")
            print(f"æ‰¾åˆ° {len(data)} æ¡æ–°é—»")
            
            processed_news = []
            for i, item in enumerate(data):
                print(f"å¤„ç†è¿›åº¦: {i+1}/{len(data)}")
                
                # ç¿»è¯‘æ ‡é¢˜
                original_title = item.get('title', '')
                translated_title = self.translate_text(original_title)
                
                # æ„å»ºæ ‡å‡†åŒ–æ ¼å¼
                news_item = {
                    'title_original': original_title,
                    'title_translated': translated_title,
                    'link': item.get('link', ''),
                    'publish_date': item.get('publish_date', ''),
                    'source': 'PV Magazine',
                    'content_type': item.get('content_type', 'news'),
                    'file_source': os.path.basename(filename)
                }
                
                processed_news.append(news_item)
                print(f"  âœ“ PV Magazine: {original_title[:60]}...")
                
                # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                time.sleep(2)
            
            return processed_news
            
        except Exception as e:
            print(f"âŒ å¤„ç†PV Magazineæ–‡ä»¶å¤±è´¥: {e}")
            return []

    def process_irena_file(self, filename):
        """å¤„ç†IRENAæ ¼å¼çš„æ–‡ä»¶"""
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                data = json.load(f)

            print(f"å¤„ç†IRENAæ–‡ä»¶: {filename}")

            # æ”¯æŒä¸¤ç§æ ¼å¼ï¼šå­—å…¸æ ¼å¼ {"news_list": [...]} å’Œæ•°ç»„æ ¼å¼ [...]
            if isinstance(data, dict) and 'news_list' in data:
                news_list = data['news_list']
            elif isinstance(data, list):
                news_list = data
            else:
                print("âŒ IRENAæ–‡ä»¶æ ¼å¼ä¸ç¬¦åˆé¢„æœŸ")
                return []

            print(f"æ‰¾åˆ° {len(news_list)} æ¡æ–°é—»")

            processed_news = []
            for i, item in enumerate(news_list):
                print(f"å¤„ç†è¿›åº¦: {i+1}/{len(news_list)}")

                # ç¿»è¯‘æ ‡é¢˜
                original_title = item.get('title', '')
                translated_title = self.translate_text(original_title)

                # æ„å»ºæ ‡å‡†åŒ–æ ¼å¼
                news_item = {
                    'title_original': original_title,
                    'title_translated': translated_title,
                    'link': item.get('link', ''),
                    'publish_date': item.get('date', ''),
                    'source': 'IRENA',
                    'summary': item.get('summary', ''),
                    'category': item.get('category', ''),
                    'language': item.get('language', ''),
                    'file_source': os.path.basename(filename)
                }

                processed_news.append(news_item)
                print(f"  âœ“ IRENA: {original_title[:60]}...")

                # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                time.sleep(2)

            return processed_news

        except Exception as e:
            print(f"âŒ å¤„ç†IRENAæ–‡ä»¶å¤±è´¥: {e}")
            return []

    def process_iea_file(self, filename):
        """å¤„ç†IEAæ ¼å¼çš„æ–‡ä»¶"""
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            print(f"å¤„ç†IEAæ–‡ä»¶: {filename}")
            print(f"æ‰¾åˆ° {len(data)} æ¡æ–°é—»")
            
            processed_news = []
            for i, item in enumerate(data):
                print(f"å¤„ç†è¿›åº¦: {i+1}/{len(data)}")
                
                # ç¿»è¯‘æ ‡é¢˜
                original_title = item.get('title', '')
                translated_title = self.translate_text(original_title)
                
                # æ„å»ºæ ‡å‡†åŒ–æ ¼å¼
                news_item = {
                    'title_original': original_title,
                    'title_translated': translated_title,
                    'link': item.get('link', ''),
                    'publish_date': item.get('publish_date', ''),
                    'source': 'IEA',
                    'content_type': item.get('content_type', 'news'),
                    'file_source': os.path.basename(filename)
                }
                
                processed_news.append(news_item)
                print(f"  âœ“ IEA: {original_title[:60]}...")
                
                # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                time.sleep(2)
            
            return processed_news
            
        except Exception as e:
            print(f"âŒ å¤„ç†IEAæ–‡ä»¶å¤±è´¥: {e}")
            return []

    def merge_and_save_translations(self):
        """åˆå¹¶æ‰€æœ‰ç¿»è¯‘ç»“æœå¹¶ä¿å­˜ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰"""
        all_news = []
        
        # å®šä¹‰è¦å¤„ç†çš„æ–‡ä»¶
        files_to_process = [
            {
                'filename': find_latest_file('pvmagazine_*.json'),
                'processor': self.process_pv_magazine_file,
                'source': 'PV Magazine'
            },
            {
                'filename': find_latest_file('irena_*.json'),
                'processor': self.process_irena_file,
                'source': 'IRENA'
            },
            {
                'filename': find_latest_file('iea_*.json'),
                'processor': self.process_iea_file,
                'source': 'IEA'
            }
        ]
        
        total_translated = 0
        
        for file_info in files_to_process:
            filename = file_info['filename']
            processor = file_info['processor']
            source = file_info['source']
            
            if filename and os.path.exists(filename):
                print(f"\n{'='*50}")
                print(f"å¼€å§‹å¤„ç† {source} æ–‡ä»¶: {os.path.basename(filename)}")
                print(f"{'='*50}")
                
                news_items = processor(filename)
                all_news.extend(news_items)
                total_translated += len(news_items)
                
                print(f"âœ… {source} å¤„ç†å®Œæˆ: {len(news_items)} æ¡æ–°é—»")
            else:
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
    
    # æ„å»ºæœ€ç»ˆè¾“å‡ºç»“æ„
        output_data = {
            'merge_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'total_news': len(all_news),
            'total_translated': total_translated,
            'sources': {
                'PV Magazine': len([n for n in all_news if n['source'] == 'PV Magazine']),
                'IRENA': len([n for n in all_news if n['source'] == 'IRENA']),
                'IEA': len([n for n in all_news if n['source'] == 'IEA'])
            },
            'news_list': all_news
        }
    
        # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_filename = f"translator_{timestamp}.json"
        output_filepath = output_filename
    
        # ä¿å­˜åˆå¹¶åçš„æ–‡ä»¶
        with open(output_filepath, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
    
        print(f"\n{'='*50}")
        print(f"ğŸ‰ æ‰€æœ‰æ–‡ä»¶ç¿»è¯‘åˆå¹¶å®Œæˆï¼")
        print(f"ğŸ“Š æ€»è®¡: {len(all_news)} æ¡æ–°é—»")
        print(f"ğŸ“Š æŒ‰æ¥æºç»Ÿè®¡:")
        for source, count in output_data['sources'].items():
            print(f"   {source}: {count} æ¡")
        print(f"ğŸ’¾ ä¿å­˜åˆ°: {output_filepath}")
        print(f"{'='*50}")
    
        return output_filepath

def main():
    translator = MultiFileTranslator()
    
    # åˆå¹¶ç¿»è¯‘æ‰€æœ‰æ–‡ä»¶
    output_file = translator.merge_and_save_translations()
    
    if output_file:
        print(f"\nğŸ‰ æ‰€æœ‰æ–‡ä»¶ç¿»è¯‘åˆå¹¶å®Œæˆï¼")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
        print("ç°åœ¨ä½ å¯ä»¥åœ¨æœ€æ–°çš„ translator_*.json æ–‡ä»¶ä¸­æŸ¥çœ‹æ‰€æœ‰ç¿»è¯‘åçš„å†…å®¹ã€‚")
    else:
        print("\nâŒ ç¿»è¯‘åˆå¹¶è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ã€‚")

if __name__ == '__main__':
    main()