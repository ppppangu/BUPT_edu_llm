import glob
import hashlib
import json
import os
import random
import re
import subprocess
import sys
import threading
import time
from datetime import datetime, timedelta
from urllib.parse import quote, urljoin

import requests
from flask import Flask, jsonify, render_template, request

# å¯¼å…¥AIæ€»ç»“æ¨¡å—
try:
    from ai_summarizer import AISummarizer
    AI_ENABLED = True
except ImportError:
    print("âš ï¸ AIæ€»ç»“æ¨¡å—æœªå®‰è£…æˆ–é…ç½®ä¸æ­£ç¡®")
    AI_ENABLED = False


def find_latest_file(pattern, directory="output/individual"):
    """æŸ¥æ‰¾æŒ‡å®šæ¨¡å¼çš„æœ€æ–°æ–‡ä»¶"""
    if not os.path.exists(directory):
        return None
    files = glob.glob(os.path.join(directory, pattern))
    if not files:
        return None
    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
    files.sort(key=os.path.getmtime, reverse=True)
    return files[0]


def find_latest_translator_file(directory="."):
    """æŸ¥æ‰¾æœ€æ–°çš„ç¿»è¯‘æ–‡ä»¶"""
    return find_latest_file("translator_*.json", directory)


# Pythonè·¯å¾„é…ç½®å·²ç§»é™¤ - ä¸éœ€è¦æ‰‹åŠ¨æ·»åŠ ç³»ç»ŸPythonè·¯å¾„

app = Flask(__name__)

# å…¨å±€å˜é‡å­˜å‚¨æ–°é—»æ•°æ®å’Œçˆ¬è™«çŠ¶æ€
news_data = []
irena_news_data = []
translated_news_data = []  # æ–°å¢ï¼šå­˜å‚¨ç¿»è¯‘åˆå¹¶åçš„æ–°é—»æ•°æ®
is_crawling = False
is_irena_crawling = False
last_update_time = None
last_irena_update_time = None
last_translated_update_time = None  # æ–°å¢ï¼šç¿»è¯‘æ•°æ®æ›´æ–°æ—¶é—´
last_manual_refresh_time = None  # æœ€åä¸€æ¬¡æ‰‹åŠ¨åˆ·æ–°çš„æ—¶é—´
MANUAL_REFRESH_COOLDOWN = 600  # æ‰‹åŠ¨åˆ·æ–°å†·å´æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œ10åˆ†é’Ÿ

# AIæ€»ç»“æ•°æ®
domestic_ai_summary = {}  # å›½å†…æ–°é—»AIæ€»ç»“
international_ai_summary = {}  # å›½é™…æ–°é—»AIæ€»ç»“

# æ•°æ®æ–‡ä»¶å“ˆå¸Œå€¼ç¼“å­˜
file_hashes = {"combined": None, "irena": None, "translator": None}

# æ•°æ®æ–‡ä»¶è·¯å¾„ - ä¿®å¤è·¯å¾„é—®é¢˜
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_FILE = find_latest_file("combined_*.json") or os.path.join(
    BASE_DIR, "combined_news.json"
)
IRENA_DATA_FILE = find_latest_file("irena_*.json") or os.path.join(
    BASE_DIR, "irena_news_load_more.json"
)
IRENA_TRANSLATED_FILE = find_latest_file("irena_*_translated.json") or os.path.join(
    BASE_DIR, "irena_translated.json"
)  # å®šä¹‰IRENAç¿»è¯‘æ–‡ä»¶
TRANSLATED_FILE = find_latest_translator_file() or os.path.join(
    BASE_DIR, "translator.json"
)  # æ–°å¢ï¼šç¿»è¯‘åˆå¹¶æ–‡ä»¶

# AIæ€»ç»“æ–‡ä»¶è·¯å¾„
AI_SUMMARY_DOMESTIC_FILE = os.path.join(BASE_DIR, "summary_domestic.json")
AI_SUMMARY_INTERNATIONAL_FILE = os.path.join(BASE_DIR, "summary_international.json")

print(f"ğŸ“ æ•°æ®æ–‡ä»¶è·¯å¾„: {DATA_FILE}")
print(f"ğŸ“ IRENAæ•°æ®æ–‡ä»¶è·¯å¾„: {IRENA_DATA_FILE}")
print(f"ğŸ“ IRENAç¿»è¯‘æ–‡ä»¶è·¯å¾„: {IRENA_TRANSLATED_FILE}")
print(f"ğŸ“ ç¿»è¯‘åˆå¹¶æ–‡ä»¶è·¯å¾„: {TRANSLATED_FILE}")
print(f"ğŸ“ å›½å†…AIæ€»ç»“æ–‡ä»¶: {AI_SUMMARY_DOMESTIC_FILE}")
print(f"ğŸ“ å›½é™…AIæ€»ç»“æ–‡ä»¶: {AI_SUMMARY_INTERNATIONAL_FILE}")


# ç¿»è¯‘ç›¸å…³é…ç½®
class Translator:
    def __init__(self):
        self.cache_file = os.path.join(BASE_DIR, "translation_cache.json")
        self.translation_cache = self._load_cache()

    def _load_cache(self):
        """åŠ è½½ç¿»è¯‘ç¼“å­˜"""
        try:
            if os.path.exists(self.cache_file):
                with open(self.cache_file, "r", encoding="utf-8") as f:
                    return json.load(f)
        except Exception:
            pass
        return {}

    def _save_cache(self):
        """ä¿å­˜ç¿»è¯‘ç¼“å­˜"""
        try:
            with open(self.cache_file, "w", encoding="utf-8") as f:
                json.dump(self.translation_cache, f, ensure_ascii=False, indent=2)
        except Exception:
            pass

    def _get_cache_key(self, text, target_lang):
        """ç”Ÿæˆç¼“å­˜é”®"""
        text_hash = hashlib.md5(f"{text}_{target_lang}".encode("utf-8")).hexdigest()
        return text_hash

    def translate_text(self, text, target_lang="zh-cn"):
        """ç¿»è¯‘æ–‡æœ¬åˆ°ç›®æ ‡è¯­è¨€"""
        if not text or not text.strip():
            return text

        # æ£€æŸ¥ç¼“å­˜
        cache_key = self._get_cache_key(text, target_lang)
        if cache_key in self.translation_cache:
            return self.translation_cache[cache_key]

        # ä½¿ç”¨googletransè¿›è¡Œç¿»è¯‘
        try:
            from googletrans import Translator

            translator = Translator()
            result = translator.translate(text, dest=target_lang)

            if result and result.text:
                # ç¼“å­˜ç»“æœ
                self.translation_cache[cache_key] = result.text
                self._save_cache()
                return result.text
            else:
                return text

        except Exception as e:
            print(f"Googletransç¿»è¯‘å¤±è´¥: {e}")
            # ç¿»è¯‘å¤±è´¥æ—¶è¿”å›åŸå§‹æ–‡æœ¬
            return text

    def translate_news_item(self, news_item):
        """ç¿»è¯‘æ–°é—»æ¡ç›®"""
        try:
            translated_item = news_item.copy()

            # ç¿»è¯‘æ ‡é¢˜
            if "title" in news_item and news_item["title"]:
                translated_title = self.translate_text(news_item["title"], "zh-cn")
                translated_item["title_translated"] = translated_title
                translated_item["title_original"] = news_item["title"]
            else:
                translated_item["title_translated"] = news_item.get("title", "")
                translated_item["title_original"] = news_item.get("title", "")

            # ç¿»è¯‘æè¿°/æ‘˜è¦
            if "summary" in news_item and news_item["summary"]:
                translated_summary = self.translate_text(news_item["summary"], "zh-cn")
                translated_item["summary_translated"] = translated_summary
                translated_item["summary_original"] = news_item["summary"]
            elif "description" in news_item and news_item["description"]:
                translated_summary = self.translate_text(
                    news_item["description"], "zh-cn"
                )
                translated_item["summary_translated"] = translated_summary
                translated_item["summary_original"] = news_item["description"]
            else:
                translated_item["summary_translated"] = news_item.get(
                    "summary", ""
                ) or news_item.get("description", "")
                translated_item["summary_original"] = news_item.get(
                    "summary", ""
                ) or news_item.get("description", "")

            return translated_item
        except Exception as e:
            print(f"ç¿»è¯‘æ–°é—»æ¡ç›®å¤±è´¥: {e}")
            # è¿”å›åŸå§‹æ•°æ®
            news_item["title_translated"] = news_item.get("title", "")
            news_item["summary_translated"] = news_item.get(
                "summary", ""
            ) or news_item.get("description", "")
            return news_item


# åˆ›å»ºç¿»è¯‘å™¨å®ä¾‹
translator = Translator()


def calculate_file_hash(filepath):
    """è®¡ç®—æ–‡ä»¶çš„MD5å“ˆå¸Œå€¼"""
    if not os.path.exists(filepath):
        return None
    try:
        with open(filepath, "rb") as f:
            file_hash = hashlib.md5(f.read()).hexdigest()
        return file_hash
    except Exception as e:
        print(f"âŒ è®¡ç®—æ–‡ä»¶å“ˆå¸Œå¤±è´¥ {filepath}: {e}")
        return None


def check_and_reload_data():
    """æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦æœ‰æ›´æ–°ï¼Œå¦‚æœæœ‰åˆ™é‡æ–°åŠ è½½"""
    global file_hashes, news_data, irena_news_data, translated_news_data
    global last_update_time, last_irena_update_time, last_translated_update_time

    reload_flags = {"combined": False, "irena": False, "translator": False}

    # æ£€æŸ¥combinedæ–‡ä»¶
    latest_combined = find_latest_file("combined_*.json") or DATA_FILE
    if os.path.exists(latest_combined):
        current_hash = calculate_file_hash(latest_combined)
        if current_hash and current_hash != file_hashes["combined"]:
            print(f"ğŸ”„ æ£€æµ‹åˆ°combinedæ•°æ®æ–‡ä»¶æ›´æ–°: {latest_combined}")
            file_hashes["combined"] = current_hash
            reload_flags["combined"] = True

    # æ£€æŸ¥irenaç¿»è¯‘æ–‡ä»¶
    latest_irena_translated = (
        find_latest_file("irena_*_translated.json") or IRENA_TRANSLATED_FILE
    )
    if os.path.exists(latest_irena_translated):
        current_hash = calculate_file_hash(latest_irena_translated)
        if current_hash and current_hash != file_hashes["irena"]:
            print(f"ğŸ”„ æ£€æµ‹åˆ°IRENAæ•°æ®æ–‡ä»¶æ›´æ–°: {latest_irena_translated}")
            file_hashes["irena"] = current_hash
            reload_flags["irena"] = True

    # æ£€æŸ¥translatoræ–‡ä»¶
    latest_translator = find_latest_translator_file() or TRANSLATED_FILE
    if os.path.exists(latest_translator):
        current_hash = calculate_file_hash(latest_translator)
        if current_hash and current_hash != file_hashes["translator"]:
            print(f"ğŸ”„ æ£€æµ‹åˆ°ç¿»è¯‘æ•°æ®æ–‡ä»¶æ›´æ–°: {latest_translator}")
            file_hashes["translator"] = current_hash
            reload_flags["translator"] = True

    # æ ¹æ®æ ‡å¿—é‡æ–°åŠ è½½æ•°æ®
    if reload_flags["combined"]:
        if load_news_from_file():
            last_update_time = datetime.now()
            print(f"âœ… å·²é‡æ–°åŠ è½½combinedæ•°æ®: {len(news_data)} æ¡")

    if reload_flags["irena"]:
        if load_irena_news_from_file():
            last_irena_update_time = datetime.now()
            print(f"âœ… å·²é‡æ–°åŠ è½½IRENAæ•°æ®: {len(irena_news_data)} æ¡")

    if reload_flags["translator"]:
        if load_translated_news_from_file():
            last_translated_update_time = datetime.now()
            print(f"âœ… å·²é‡æ–°åŠ è½½ç¿»è¯‘æ•°æ®: {len(translated_news_data)} æ¡")

    return any(reload_flags.values())


def load_news_from_file():
    """ä»JSONæ–‡ä»¶åŠ è½½å›½å†…æ–°é—»æ•°æ®"""
    global news_data
    try:
        # åŠ¨æ€æŸ¥æ‰¾æœ€æ–°çš„combinedæ–‡ä»¶
        latest_file = find_latest_file("combined_*.json") or DATA_FILE

        if os.path.exists(latest_file):
            with open(latest_file, "r", encoding="utf-8") as f:
                loaded_data = json.load(f)

            if isinstance(loaded_data, list):
                news_data = loaded_data
                print(f"âœ… ä» {latest_file} åŠ è½½äº† {len(news_data)} æ¡å›½å†…æ–°é—»")
                return True
            else:
                print(f"âŒ æ•°æ®æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼ŒæœŸæœ›åˆ—è¡¨ï¼Œå¾—åˆ° {type(loaded_data)}")
                return False
        else:
            print(f"âŒ æ•°æ®æ–‡ä»¶ {latest_file} ä¸å­˜åœ¨")
            alternative_files = [
                "gov_solar_news.json",
                "nea_solar_news.json",
                "solar_news.json",
            ]
            for file in alternative_files:
                alt_path = os.path.join(BASE_DIR, file)
                if os.path.exists(alt_path):
                    print(f"ğŸ” å°è¯•åŠ è½½æ›¿ä»£æ–‡ä»¶: {file}")
                    with open(alt_path, "r", encoding="utf-8") as f:
                        news_data = json.load(f)
                    print(f"âœ… ä» {file} åŠ è½½äº† {len(news_data)} æ¡æ–°é—»")
                    return True
            return False
    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®æ–‡ä»¶å¤±è´¥: {e}")
        create_test_data()
        return True


def load_irena_news_from_file():
    """ä»JSONæ–‡ä»¶åŠ è½½IRENAæ–°é—»æ•°æ®"""
    global irena_news_data
    try:
        # åŠ¨æ€æŸ¥æ‰¾æœ€æ–°çš„irenaç¿»è¯‘æ–‡ä»¶
        latest_translated_file = (
            find_latest_file("irena_*_translated.json") or IRENA_TRANSLATED_FILE
        )
        latest_irena_file = find_latest_file("irena_*.json") or IRENA_DATA_FILE

        # ä¼˜å…ˆå°è¯•åŠ è½½ç¿»è¯‘åçš„æ–‡ä»¶
        if os.path.exists(latest_translated_file):
            print(f"ğŸ” æ‰¾åˆ°ç¿»è¯‘åçš„æ–‡ä»¶: {latest_translated_file}")
            with open(latest_translated_file, "r", encoding="utf-8") as f:
                loaded_data = json.load(f)

            if isinstance(loaded_data, list):
                irena_news_data = loaded_data
                print(f"âœ… ä»ç¿»è¯‘æ–‡ä»¶åŠ è½½äº† {len(irena_news_data)} æ¡IRENAæ–°é—»")
                return True

        # å¦‚æœç¿»è¯‘æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå›é€€åˆ°åŸå§‹æ–‡ä»¶
        if os.path.exists(latest_irena_file):
            with open(latest_irena_file, "r", encoding="utf-8") as f:
                loaded_data = json.load(f)

            if isinstance(loaded_data, list):
                irena_news_data = loaded_data
            elif isinstance(loaded_data, dict) and "news_list" in loaded_data:
                irena_news_data = loaded_data["news_list"]
            else:
                print(f"âŒ IRENAæ•°æ®æ–‡ä»¶æ ¼å¼é”™è¯¯: {type(loaded_data)}")
                return False

            print(
                f"âœ… ä» {latest_irena_file} åŠ è½½äº† {len(irena_news_data)} æ¡IRENAæ–°é—»"
            )
            return True
        else:
            print(f"âŒ IRENAæ•°æ®æ–‡ä»¶ {latest_irena_file} ä¸å­˜åœ¨")
            irena_alternative_files = [
                "irena_news.json",
                "irena_news_comprehensive.json",
                "irena_news_paginated.json",
            ]
            for file in irena_alternative_files:
                alt_path = os.path.join(BASE_DIR, file)
                if os.path.exists(alt_path):
                    print(f"ğŸ” å°è¯•åŠ è½½IRENAæ›¿ä»£æ–‡ä»¶: {file}")
                    with open(alt_path, "r", encoding="utf-8") as f:
                        alt_data = json.load(f)

                    if isinstance(alt_data, list):
                        irena_news_data = alt_data
                    elif isinstance(alt_data, dict) and "news_list" in alt_data:
                        irena_news_data = alt_data["news_list"]
                    else:
                        continue

                    print(f"âœ… ä» {file} åŠ è½½äº† {len(irena_news_data)} æ¡IRENAæ–°é—»")
                    return True
            return False
    except Exception as e:
        print(f"âŒ åŠ è½½IRENAæ•°æ®æ–‡ä»¶å¤±è´¥: {e}")
        return False


def load_translated_news_from_file():
    """ä»ç¿»è¯‘åˆå¹¶æ–‡ä»¶åŠ è½½æ•°æ®"""
    global translated_news_data, last_translated_update_time
    try:
        # åŠ¨æ€æŸ¥æ‰¾æœ€æ–°çš„translatoræ–‡ä»¶
        latest_file = find_latest_translator_file() or TRANSLATED_FILE

        if os.path.exists(latest_file):
            with open(latest_file, "r", encoding="utf-8") as f:
                loaded_data = json.load(f)

            if isinstance(loaded_data, dict) and "news_list" in loaded_data:
                translated_news_data = loaded_data["news_list"]
                print(
                    f"âœ… ä»ç¿»è¯‘æ–‡ä»¶ {latest_file} åŠ è½½äº† {len(translated_news_data)} æ¡å¤šæ¥æºæ–°é—»"
                )
                last_translated_update_time = datetime.now()
                return True
            elif isinstance(loaded_data, list):
                translated_news_data = loaded_data
                print(
                    f"âœ… ä»ç¿»è¯‘æ–‡ä»¶ {latest_file} åŠ è½½äº† {len(translated_news_data)} æ¡å¤šæ¥æºæ–°é—»"
                )
                last_translated_update_time = datetime.now()
                return True
            else:
                print(f"âŒ ç¿»è¯‘æ–‡ä»¶æ ¼å¼é”™è¯¯: {type(loaded_data)}")
                return False
        else:
            print(f"âŒ ç¿»è¯‘æ–‡ä»¶ {latest_file} ä¸å­˜åœ¨")
            return False
    except Exception as e:
        print(f"âŒ åŠ è½½ç¿»è¯‘æ–‡ä»¶å¤±è´¥: {e}")
        return False


def create_test_data():
    """åˆ›å»ºæµ‹è¯•æ•°æ®"""
    global news_data
    print("ğŸ”„ åˆ›å»ºæµ‹è¯•æ•°æ®...")

    test_news = []

    nea_titles = [
        "å›½å®¶èƒ½æºå±€å‘å¸ƒå…‰ä¼äº§ä¸šå‘å±•æŒ‡å¯¼æ„è§",
        "å…‰ä¼å‘ç”µé¡¹ç›®å®¡æ‰¹æµç¨‹ä¼˜åŒ–æ–¹æ¡ˆ",
        "æ–°èƒ½æºæ”¿ç­–æ”¯æŒå…‰ä¼æŠ€æœ¯åˆ›æ–°",
        "åˆ†å¸ƒå¼å…‰ä¼å‘ç”µæ¨å¹¿åº”ç”¨é€šçŸ¥",
        "å…‰ä¼æ‰¶è´«é¡¹ç›®æˆæ•ˆæ˜¾è‘—",
        "å¤ªé˜³èƒ½å…‰ä¼äº§ä¸šé“¾å‘å±•æŠ¥å‘Š",
        "å…‰ä¼ç”µç«™å»ºè®¾æ ‡å‡†æ›´æ–°",
        "å¯å†ç”Ÿèƒ½æºå…‰ä¼å‘ç”µç»Ÿè®¡",
        "å…‰ä¼ç»„ä»¶è´¨é‡ç›‘ç®¡åŠ å¼º",
        "å…‰ä¼äº§ä¸šå›½é™…åˆä½œäº¤æµ",
    ]

    gov_titles = [
        "å›½åŠ¡é™¢æ¨è¿›å…‰ä¼äº§ä¸šå‘å±•æ”¿ç­–",
        "å…‰ä¼å‘ç”µè¡¥è´´æ”¿ç­–è°ƒæ•´é€šçŸ¥",
        "æ–°èƒ½æºå…‰ä¼æŠ€æœ¯åˆ›æ–°æ”¯æŒè®¡åˆ’",
        "åˆ†å¸ƒå¼å…‰ä¼å‘ç”µæ¨å¹¿åº”ç”¨",
        "å…‰ä¼æ‰¶è´«åŠ©åŠ›ä¹¡æ‘æŒ¯å…´",
        "å¤ªé˜³èƒ½å…‰ä¼äº§ä¸šå‘å±•è§„åˆ’",
        "å…‰ä¼ç”µç«™å®‰å…¨è¿è¡Œç®¡ç†",
        "å¯å†ç”Ÿèƒ½æºå…‰ä¼å‘ç”µæ•°æ®",
        "å…‰ä¼ç»„ä»¶è´¨é‡æ ‡å‡†æå‡",
        "å…‰ä¼äº§ä¸šå›½é™…åˆä½œæˆæœ",
    ]

    for i, title in enumerate(nea_titles):
        date = datetime(2024, 9, 1) + timedelta(days=random.randint(0, 47))
        test_news.append(
            {
                "title": title,
                "link": f"https://www.nea.gov.cn/news_{i}",
                "date": date.strftime("%Y-%m-%d"),
                "source": "å›½å®¶èƒ½æºå±€",
            }
        )

    for i, title in enumerate(gov_titles):
        date = datetime(2024, 9, 1) + timedelta(days=random.randint(0, 47))
        test_news.append(
            {
                "title": title,
                "link": f"https://www.gov.cn/news_{i}",
                "date": date.strftime("%Y-%m-%d"),
                "source": "ä¸­å›½æ”¿åºœç½‘",
            }
        )

    news_data = test_news
    print(f"âœ… åˆ›å»ºäº† {len(news_data)} æ¡æµ‹è¯•æ•°æ®")


def save_news_to_file(data, filename=DATA_FILE):
    """ä¿å­˜æ–°é—»æ•°æ®åˆ°JSONæ–‡ä»¶"""
    try:
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ° {filename}")
        return True
    except Exception as e:
        print(f"âŒ ä¿å­˜æ•°æ®æ–‡ä»¶å¤±è´¥: {e}")
        return False


def run_crawler():
    """è¿è¡Œå›½å†…çˆ¬è™«è„šæœ¬"""
    try:
        print("ğŸš€ å¯åŠ¨å›½å†…çˆ¬è™«è„šæœ¬...")
        crawler_path = os.path.join(BASE_DIR, "combined_crawler.py")
        print(f"ğŸ“ çˆ¬è™«è„šæœ¬è·¯å¾„: {crawler_path}")

        result = subprocess.run(
            [sys.executable, crawler_path],
            capture_output=True,
            text=True,
            encoding="utf-8",
            cwd=BASE_DIR,
        )

        print(f"ğŸ“Š çˆ¬è™«è¾“å‡º: {result.stdout}")
        if result.stderr:
            print(f"âŒ çˆ¬è™«é”™è¯¯: {result.stderr}")

        if result.returncode == 0:
            print("âœ… å›½å†…çˆ¬è™«è„šæœ¬æ‰§è¡ŒæˆåŠŸ")
            return True
        else:
            print(f"âŒ å›½å†…çˆ¬è™«è„šæœ¬æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
            return False
    except Exception as e:
        print(f"âŒ è¿è¡Œå›½å†…çˆ¬è™«è„šæœ¬æ—¶å‡ºé”™: {e}")
        return False


def run_irena_crawler():
    """è¿è¡ŒIRENAçˆ¬è™«è„šæœ¬"""
    try:
        print("ğŸš€ å¯åŠ¨IRENAçˆ¬è™«è„šæœ¬...")
        crawler_path = os.path.join(BASE_DIR, "irena_crawler.py")

        result = subprocess.run(
            [sys.executable, crawler_path],
            capture_output=True,
            text=True,
            encoding="utf-8",
            cwd=BASE_DIR,
        )

        print(f"ğŸ“Š IRENAçˆ¬è™«è¾“å‡º: {result.stdout}")
        if result.stderr:
            print(f"âŒ IRENAçˆ¬è™«é”™è¯¯: {result.stderr}")

        if result.returncode == 0:
            print("âœ… IRENAçˆ¬è™«è„šæœ¬æ‰§è¡ŒæˆåŠŸ")
            return True
        else:
            print(f"âŒ IRENAçˆ¬è™«è„šæœ¬æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
            return False
    except Exception as e:
        print(f"âŒ è¿è¡ŒIRENAçˆ¬è™«è„šæœ¬æ—¶å‡ºé”™: {e}")
        return False


def initialize_data():
    """åˆå§‹åŒ–æ•°æ®"""
    global \
        news_data, \
        irena_news_data, \
        translated_news_data, \
        last_update_time, \
        last_irena_update_time, \
        last_translated_update_time
    global file_hashes

    print("ğŸ”„ åˆå§‹åŒ–æ•°æ®...")

    # åˆå§‹åŒ–combinedæ•°æ®å’Œå“ˆå¸Œ
    if load_news_from_file():
        last_update_time = datetime.now()
        latest_combined = find_latest_file("combined_*.json") or DATA_FILE
        file_hashes["combined"] = calculate_file_hash(latest_combined)
        print(f"âœ… å›½å†…æ•°æ®åˆå§‹åŒ–å®Œæˆ: {len(news_data)} æ¡æ–°é—»")
    else:
        print("âŒ å›½å†…æ•°æ®åˆå§‹åŒ–å¤±è´¥")

    # åˆå§‹åŒ–IRENAæ•°æ®å’Œå“ˆå¸Œ
    if load_irena_news_from_file():
        last_irena_update_time = datetime.now()
        latest_irena = (
            find_latest_file("irena_*_translated.json") or IRENA_TRANSLATED_FILE
        )
        file_hashes["irena"] = calculate_file_hash(latest_irena)
        print(f"âœ… IRENAæ•°æ®åˆå§‹åŒ–å®Œæˆ: {len(irena_news_data)} æ¡æ–°é—»")
    else:
        print("âŒ IRENAæ•°æ®åˆå§‹åŒ–å¤±è´¥")

    # åˆå§‹åŒ–ç¿»è¯‘æ•°æ®å’Œå“ˆå¸Œ
    if load_translated_news_from_file():
        last_translated_update_time = datetime.now()
        latest_translator = find_latest_translator_file() or TRANSLATED_FILE
        file_hashes["translator"] = calculate_file_hash(latest_translator)
        print(f"âœ… ç¿»è¯‘æ•°æ®åˆå§‹åŒ–å®Œæˆ: {len(translated_news_data)} æ¡æ–°é—»")
    else:
        print("âŒ ç¿»è¯‘æ•°æ®åˆå§‹åŒ–å¤±è´¥")


# åœ¨æ¨¡å—åŠ è½½æ—¶åˆå§‹åŒ–æ•°æ®ï¼ˆæ”¯æŒgunicornç­‰WSGIæœåŠ¡å™¨ï¼‰
initialize_data()

# ==================== å›½å†…æ–°é—»è·¯ç”± ====================


@app.route("/")
def index():
    return render_template("index.html")


@app.route("/news_search")
def news_search():
    return render_template("news_search.html")


@app.route("/translated_news")
def translated_news():
    return render_template("translated_news.html")


@app.route("/get_news")
def get_news():
    """è·å–ç­›é€‰åçš„å›½å†…æ–°é—»æ•°æ®"""
    global news_data

    # è‡ªåŠ¨æ£€æŸ¥å¹¶é‡æ–°åŠ è½½æ•°æ®æ–‡ä»¶ï¼ˆå¦‚æœæœ‰æ›´æ–°ï¼‰
    check_and_reload_data()

    try:
        start_date_str = request.args.get("start_date")
        end_date_str = request.args.get("end_date")
        keyword = request.args.get("keyword", "").strip()
        source_filter = request.args.get("source", "").strip()

        print(
            f"ğŸ” ç­›é€‰å‚æ•°: start_date={start_date_str}, end_date={end_date_str}, keyword={keyword}, source={source_filter}"
        )

        if not news_data:
            load_news_from_file()

        filtered_news = []
        for news in news_data:
            include = True

            if start_date_str and end_date_str:
                try:
                    news_date = datetime.strptime(news["date"], "%Y-%m-%d").date()
                    start_date = datetime.strptime(start_date_str, "%Y-%m-%d").date()
                    end_date = datetime.strptime(end_date_str, "%Y-%m-%d").date()
                    if not (start_date <= news_date <= end_date):
                        include = False
                except ValueError:
                    include = False

            if include and keyword and keyword.lower() not in news["title"].lower():
                include = False

            if include and source_filter and news["source"] != source_filter:
                include = False

            if include:
                filtered_news.append(news)

        filtered_news.sort(key=lambda x: x["date"], reverse=True)

        source_stats = {}
        for news in filtered_news:
            source = news["source"]
            source_stats[source] = source_stats.get(source, 0) + 1

        print(f"ğŸ“Š ç­›é€‰ç»“æœ: æ€»æ•°={len(news_data)}, ç­›é€‰å={len(filtered_news)}")

        return jsonify(
            {
                "success": True,
                "data": filtered_news,
                "count": len(filtered_news),
                "total_count": len(news_data),
                "filtered_source_stats": source_stats,
                "last_update": last_update_time.strftime("%Y-%m-%d %H:%M:%S")
                if last_update_time
                else None,
            }
        )

    except Exception as e:
        print(f"âŒ è·å–æ–°é—»æ•°æ®é”™è¯¯: {e}")
        return jsonify({"success": False, "error": str(e)})


@app.route("/get_stats")
def get_stats():
    """è·å–å›½å†…æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
    global news_data

    try:
        source_stats = {}
        for news in news_data:
            source = news["source"]
            source_stats[source] = source_stats.get(source, 0) + 1

        return jsonify(
            {
                "success": True,
                "total_count": len(news_data),
                "source_stats": source_stats,
                "last_update": last_update_time.strftime("%Y-%m-%d %H:%M:%S")
                if last_update_time
                else None,
            }
        )

    except Exception as e:
        print(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯é”™è¯¯: {e}")
        return jsonify({"success": False, "error": str(e)})


@app.route("/refresh_news")
def refresh_news():
    """è§¦å‘å›½å†…æ–°é—»æ•°æ®æ›´æ–° - è¿è¡Œçˆ¬è™«è„šæœ¬"""
    global is_crawling, last_manual_refresh_time

    # æ£€æŸ¥å†·å´æ—¶é—´
    if last_manual_refresh_time:
        elapsed = (datetime.now() - last_manual_refresh_time).total_seconds()
        if elapsed < MANUAL_REFRESH_COOLDOWN:
            remaining = int(MANUAL_REFRESH_COOLDOWN - elapsed)
            return jsonify(
                {"success": False, "error": f"æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œè¯· {remaining} ç§’åå†è¯•"}
            )

    if is_crawling:
        return jsonify({"success": False, "error": "æ­£åœ¨æ›´æ–°ä¸­ï¼Œè¯·ç¨å€™..."})

    def crawl_news():
        global news_data, is_crawling, last_update_time

        is_crawling = True
        print("ğŸš€ å¼€å§‹è¿è¡Œçˆ¬è™«æ›´æ–°æ•°æ®...")

        try:
            if run_crawler():
                if load_news_from_file():
                    last_update_time = datetime.now()
                    print(f"ğŸ‰ æ•°æ®æ›´æ–°å®Œæˆï¼æ€»è®¡ï¼š{len(news_data)} æ¡æ–°é—»")
                else:
                    print("âŒ æ•°æ®åŠ è½½å¤±è´¥")
            else:
                print("âŒ çˆ¬è™«è¿è¡Œå¤±è´¥")

        except Exception as e:
            print(f"âŒ æ•°æ®æ›´æ–°å¤±è´¥: {e}")
        finally:
            is_crawling = False

    # æ›´æ–°æœ€ååˆ·æ–°æ—¶é—´
    last_manual_refresh_time = datetime.now()

    thread = threading.Thread(target=crawl_news)
    thread.daemon = True
    thread.start()

    return jsonify(
        {"success": True, "message": "å¼€å§‹æ›´æ–°æ•°æ®ï¼Œè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´..."}
    )


@app.route("/check_update")
def check_update():
    """æ£€æŸ¥å›½å†…æ›´æ–°çŠ¶æ€"""
    global is_crawling, last_update_time

    if is_crawling:
        return jsonify(
            {"success": True, "updated": False, "message": "æ­£åœ¨æ›´æ–°æ•°æ®..."}
        )
    else:
        if last_update_time:
            return jsonify(
                {
                    "success": True,
                    "updated": True,
                    "message": f"æ•°æ®æ›´æ–°å®Œæˆï¼æœ€åæ›´æ–°ï¼š{last_update_time.strftime('%Y-%m-%d %H:%M:%S')}",
                }
            )
        else:
            return jsonify({"success": True, "updated": True, "message": "æ•°æ®å·²å°±ç»ª"})


# ==================== IRENAæ–°é—»è·¯ç”± ====================


@app.route("/get_irena_news")
def get_irena_news():
    """è·å–ç­›é€‰åçš„IRENAæ–°é—»æ•°æ®"""
    global irena_news_data

    # è‡ªåŠ¨æ£€æŸ¥å¹¶é‡æ–°åŠ è½½æ•°æ®æ–‡ä»¶ï¼ˆå¦‚æœæœ‰æ›´æ–°ï¼‰
    check_and_reload_data()

    try:
        start_date_str = request.args.get("start_date")
        end_date_str = request.args.get("end_date")
        keyword = request.args.get("keyword", "").strip()

        print(
            f"ğŸ” IRENAç­›é€‰å‚æ•°: start_date={start_date_str}, end_date={end_date_str}, keyword={keyword}"
        )

        if not irena_news_data:
            load_irena_news_from_file()

        filtered_news = []
        for news in irena_news_data:
            include = True

            if start_date_str and end_date_str:
                try:
                    news_date_str = news.get("date", "")
                    if not news_date_str:
                        continue

                    if re.match(r"\d{4}-\d{2}-\d{2}", news_date_str):
                        news_date = datetime.strptime(news_date_str, "%Y-%m-%d").date()
                    elif re.match(r"\d{1,2}\s+\w+\s+\d{4}", news_date_str):
                        news_date = datetime.strptime(news_date_str, "%d %B %Y").date()
                    else:
                        continue

                    start_date = datetime.strptime(start_date_str, "%Y-%m-%d").date()
                    end_date = datetime.strptime(end_date_str, "%Y-%m-%d").date()

                    if not (start_date <= news_date <= end_date):
                        include = False
                except ValueError as e:
                    print(f"æ—¥æœŸè§£æé”™è¯¯: {e}, æ—¥æœŸ: {news_date_str}")
                    include = False

            if include and keyword:
                keyword_lower = keyword.lower()
                title = news.get("title", "").lower()
                summary = news.get("summary", "").lower()
                search_keyword = news.get("search_keyword", "").lower()

                if (
                    keyword_lower not in title
                    and keyword_lower not in summary
                    and keyword_lower not in search_keyword
                ):
                    include = False

            if include:
                filtered_news.append(news)

        filtered_news.sort(key=lambda x: x.get("date", ""), reverse=True)

        print(
            f"ğŸ“Š IRENAç­›é€‰ç»“æœ: æ€»æ•°={len(irena_news_data)}, ç­›é€‰å={len(filtered_news)}"
        )

        return jsonify(
            {
                "success": True,
                "data": filtered_news,
                "count": len(filtered_news),
                "total_count": len(irena_news_data),
                "last_update": last_irena_update_time.strftime("%Y-%m-%d %H:%M:%S")
                if last_irena_update_time
                else None,
            }
        )

    except Exception as e:
        print(f"âŒ è·å–IRENAæ–°é—»æ•°æ®é”™è¯¯: {e}")
        return jsonify({"success": False, "error": str(e)})


@app.route("/refresh_irena_news")
def refresh_irena_news():
    """è§¦å‘IRENAæ–°é—»æ•°æ®æ›´æ–°"""
    global is_irena_crawling, last_manual_refresh_time

    # æ£€æŸ¥å†·å´æ—¶é—´
    if last_manual_refresh_time:
        elapsed = (datetime.now() - last_manual_refresh_time).total_seconds()
        if elapsed < MANUAL_REFRESH_COOLDOWN:
            remaining = int(MANUAL_REFRESH_COOLDOWN - elapsed)
            return jsonify(
                {"success": False, "error": f"æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œè¯· {remaining} ç§’åå†è¯•"}
            )

    if is_irena_crawling:
        return jsonify({"success": False, "error": "IRENAæ•°æ®æ­£åœ¨æ›´æ–°ä¸­ï¼Œè¯·ç¨å€™..."})

    def crawl_irena_news():
        global irena_news_data, is_irena_crawling, last_irena_update_time

        is_irena_crawling = True
        print("ğŸš€ å¼€å§‹è¿è¡ŒIRENAçˆ¬è™«æ›´æ–°æ•°æ®...")

        try:
            if run_irena_crawler():
                if load_irena_news_from_file():
                    last_irena_update_time = datetime.now()
                    print(f"ğŸ‰ IRENAæ•°æ®æ›´æ–°å®Œæˆï¼æ€»è®¡ï¼š{len(irena_news_data)} æ¡æ–°é—»")
                else:
                    print("âŒ IRENAæ•°æ®åŠ è½½å¤±è´¥")
            else:
                print("âŒ IRENAçˆ¬è™«è¿è¡Œå¤±è´¥")

        except Exception as e:
            print(f"âŒ IRENAæ•°æ®æ›´æ–°å¤±è´¥: {e}")
        finally:
            is_irena_crawling = False

    # æ›´æ–°æœ€ååˆ·æ–°æ—¶é—´
    last_manual_refresh_time = datetime.now()

    thread = threading.Thread(target=crawl_irena_news)
    thread.daemon = True
    thread.start()

    return jsonify(
        {"success": True, "message": "å¼€å§‹æ›´æ–°IRENAæ•°æ®ï¼Œè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´..."}
    )


@app.route("/check_irena_update")
def check_irena_update():
    """æ£€æŸ¥IRENAæ›´æ–°çŠ¶æ€"""
    global is_irena_crawling, last_irena_update_time

    if is_irena_crawling:
        return jsonify(
            {"success": True, "updated": False, "message": "æ­£åœ¨æ›´æ–°IRENAæ•°æ®..."}
        )
    else:
        if last_irena_update_time:
            return jsonify(
                {
                    "success": True,
                    "updated": True,
                    "message": f"IRENAæ•°æ®æ›´æ–°å®Œæˆï¼æœ€åæ›´æ–°ï¼š{last_irena_update_time.strftime('%Y-%m-%d %H:%M:%S')}",
                }
            )
        else:
            return jsonify(
                {"success": True, "updated": True, "message": "IRENAæ•°æ®å·²å°±ç»ª"}
            )


# ==================== ç¿»è¯‘åˆå¹¶æ–°é—»è·¯ç”± ====================


@app.route("/refresh_translated_news")
def refresh_translated_news():
    """é‡æ–°åŠ è½½æœ€æ–°çš„ç¿»è¯‘æ–‡ä»¶ï¼ˆä¸è¿è¡Œçˆ¬è™«ï¼Œåªåˆ·æ–°æ•°æ®ï¼‰"""
    global translated_news_data, last_translated_update_time, last_manual_refresh_time

    # æ£€æŸ¥å†·å´æ—¶é—´
    if last_manual_refresh_time:
        elapsed = (datetime.now() - last_manual_refresh_time).total_seconds()
        if elapsed < MANUAL_REFRESH_COOLDOWN:
            remaining = int(MANUAL_REFRESH_COOLDOWN - elapsed)
            return jsonify(
                {"success": False, "error": f"æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œè¯· {remaining} ç§’åå†è¯•"}
            )

    try:
        print("ğŸ”„ å¼€å§‹åˆ·æ–°ç¿»è¯‘æ•°æ®...")

        # æ›´æ–°æœ€ååˆ·æ–°æ—¶é—´
        last_manual_refresh_time = datetime.now()

        # é‡æ–°åŠ è½½æœ€æ–°çš„ç¿»è¯‘æ–‡ä»¶
        if load_translated_news_from_file():
            print(f"âœ… ç¿»è¯‘æ•°æ®åˆ·æ–°æˆåŠŸï¼æ€»è®¡ï¼š{len(translated_news_data)} æ¡æ–°é—»")
            return jsonify(
                {
                    "success": True,
                    "message": f"æ•°æ®åˆ·æ–°æˆåŠŸï¼å…± {len(translated_news_data)} æ¡æ–°é—»",
                    "count": len(translated_news_data),
                    "last_update": last_translated_update_time.strftime(
                        "%Y-%m-%d %H:%M:%S"
                    )
                    if last_translated_update_time
                    else None,
                }
            )
        else:
            print("âŒ ç¿»è¯‘æ•°æ®åŠ è½½å¤±è´¥")
            return jsonify({"success": False, "error": "æ•°æ®åŠ è½½å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"})

    except Exception as e:
        print(f"âŒ åˆ·æ–°ç¿»è¯‘æ•°æ®å¤±è´¥: {e}")
        return jsonify({"success": False, "error": str(e)})


@app.route("/get_translated_news")
def get_translated_news():
    """è·å–ç¿»è¯‘åˆå¹¶åçš„å¤šæ¥æºæ–°é—»æ•°æ®"""
    global translated_news_data

    # è‡ªåŠ¨æ£€æŸ¥å¹¶é‡æ–°åŠ è½½æ•°æ®æ–‡ä»¶ï¼ˆå¦‚æœæœ‰æ›´æ–°ï¼‰
    check_and_reload_data()

    try:
        start_date_str = request.args.get("start_date")
        end_date_str = request.args.get("end_date")
        keyword = request.args.get("keyword", "").strip()
        source_filter = request.args.get("source", "").strip()

        print(
            f"ğŸ” ç¿»è¯‘æ–°é—»ç­›é€‰å‚æ•°: start_date={start_date_str}, end_date={end_date_str}, keyword={keyword}, source={source_filter}"
        )

        if not translated_news_data:
            load_translated_news_from_file()

        filtered_news = []
        for news in translated_news_data:
            include = True

            # æ—¥æœŸç­›é€‰
            if start_date_str and end_date_str:
                try:
                    news_date_str = news.get("publish_date", "") or news.get("date", "")
                    if not news_date_str:
                        continue

                    if re.match(r"\d{4}-\d{2}-\d{2}", news_date_str):
                        news_date = datetime.strptime(news_date_str, "%Y-%m-%d").date()
                        start_date = datetime.strptime(
                            start_date_str, "%Y-%m-%d"
                        ).date()
                        end_date = datetime.strptime(end_date_str, "%Y-%m-%d").date()

                        if not (start_date <= news_date <= end_date):
                            include = False
                except ValueError as e:
                    print(f"æ—¥æœŸè§£æé”™è¯¯: {e}, æ—¥æœŸ: {news_date_str}")
                    include = False

            # å…³é”®è¯ç­›é€‰
            if include and keyword:
                keyword_lower = keyword.lower()
                title_original = news.get("title_original", "").lower()
                title_translated = news.get("title_translated", "").lower()
                summary = news.get("summary", "").lower()

                if (
                    keyword_lower not in title_original
                    and keyword_lower not in title_translated
                    and keyword_lower not in summary
                ):
                    include = False

            # æ¥æºç­›é€‰
            if (
                include
                and source_filter
                and news.get("source", "").lower() != source_filter.lower()
            ):
                include = False

            if include:
                filtered_news.append(news)

        # æŒ‰æ—¥æœŸæ’åº
        filtered_news.sort(
            key=lambda x: x.get("publish_date", "") or x.get("date", ""), reverse=True
        )

        # ç»Ÿè®¡å„æ¥æºæ•°é‡
        source_stats = {}
        for news in filtered_news:
            source = news.get("source", "Unknown")
            source_stats[source] = source_stats.get(source, 0) + 1

        print(
            f"ğŸ“Š ç¿»è¯‘æ–°é—»ç­›é€‰ç»“æœ: æ€»æ•°={len(translated_news_data)}, ç­›é€‰å={len(filtered_news)}"
        )

        return jsonify(
            {
                "success": True,
                "data": filtered_news,
                "count": len(filtered_news),
                "total_count": len(translated_news_data),
                "source_stats": source_stats,
                "last_update": last_translated_update_time.strftime("%Y-%m-%d %H:%M:%S")
                if last_translated_update_time
                else None,
            }
        )

    except Exception as e:
        print(f"âŒ è·å–ç¿»è¯‘æ–°é—»æ•°æ®é”™è¯¯: {e}")
        return jsonify({"success": False, "error": str(e)})


@app.route("/get_translated_stats")
def get_translated_stats():
    """è·å–ç¿»è¯‘æ–°é—»ç»Ÿè®¡ä¿¡æ¯"""
    global translated_news_data

    try:
        source_stats = {}
        for news in translated_news_data:
            source = news.get("source", "Unknown")
            source_stats[source] = source_stats.get(source, 0) + 1

        return jsonify(
            {
                "success": True,
                "total_count": len(translated_news_data),
                "source_stats": source_stats,
                "last_update": last_translated_update_time.strftime("%Y-%m-%d %H:%M:%S")
                if last_translated_update_time
                else None,
            }
        )

    except Exception as e:
        print(f"âŒ è·å–ç¿»è¯‘ç»Ÿè®¡ä¿¡æ¯é”™è¯¯: {e}")
        return jsonify({"success": False, "error": str(e)})


@app.route("/translate_news")
def translate_news():
    """ç¿»è¯‘å•æ¡æ–°é—»"""
    try:
        title = request.args.get("title", "")
        description = request.args.get("description", "")

        # è°ƒç”¨ç¿»è¯‘å™¨è¿›è¡Œå®é™…ç¿»è¯‘
        translated_title = translator.translate_text(title, "zh-cn")
        translated_description = (
            translator.translate_text(description, "zh-cn") if description else ""
        )

        return jsonify(
            {
                "success": True,
                "translated_title": translated_title,
                "translated_description": translated_description,
                "original_title": title,
                "original_description": description,
            }
        )
    except Exception as e:
        return jsonify({"success": False, "error": str(e)})


# ==================== AIæ€»ç»“ç›¸å…³åŠŸèƒ½ ====================


def load_ai_summary(file_path):
    """ä»æ–‡ä»¶åŠ è½½AIæ€»ç»“ï¼ˆè¿”å›ä»Šå¤©çš„ï¼Œå¦‚æœæ²¡æœ‰å°±è¿”å›æœ€æ–°çš„ï¼‰"""
    try:
        if os.path.exists(file_path):
            with open(file_path, "r", encoding="utf-8") as f:
                data = json.load(f)

            # å¦‚æœæ˜¯åˆ—è¡¨æ ¼å¼ï¼ˆæ–°æ ¼å¼ï¼‰
            if isinstance(data, list) and len(data) > 0:
                today = datetime.now().strftime("%Y-%m-%d")
                # ä¼˜å…ˆè¿”å›ä»Šå¤©çš„ç®€æŠ¥
                for item in data:
                    if item.get("date") == today:
                        print(f"âœ… AIæ€»ç»“åŠ è½½æˆåŠŸ (ä»Šæ—¥): {file_path}")
                        return item
                # å¦‚æœæ²¡æœ‰ä»Šå¤©çš„ï¼Œè¿”å›æœ€æ–°çš„ï¼ˆåˆ—è¡¨ç¬¬ä¸€æ¡ï¼‰
                print(f"âœ… AIæ€»ç»“åŠ è½½æˆåŠŸ (æœ€æ–°): {file_path}")
                return data[0]

            # å…¼å®¹æ—§æ ¼å¼ï¼ˆå­—å…¸ï¼‰
            print(f"âœ… AIæ€»ç»“åŠ è½½æˆåŠŸ: {file_path}")
            return data
        else:
            print(f"âš ï¸ AIæ€»ç»“æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return {}
    except Exception as e:
        print(f"âŒ åŠ è½½AIæ€»ç»“å¤±è´¥: {e}")
        return {}


@app.route("/get_ai_summary/<news_type>")
def get_ai_summary(news_type):
    """
    è·å–AIæ€»ç»“
    news_type: domestic(å›½å†…) æˆ– international(å›½é™…)
    """
    global domestic_ai_summary, international_ai_summary

    try:
        if news_type == "domestic":
            # é‡æ–°åŠ è½½å›½å†…æ–°é—»AIæ€»ç»“
            summary = load_ai_summary(AI_SUMMARY_DOMESTIC_FILE)
            domestic_ai_summary = summary
        elif news_type == "international":
            # é‡æ–°åŠ è½½å›½é™…æ–°é—»AIæ€»ç»“
            summary = load_ai_summary(AI_SUMMARY_INTERNATIONAL_FILE)
            international_ai_summary = summary
        else:
            return jsonify({"success": False, "error": "æ— æ•ˆçš„æ–°é—»ç±»å‹"})

        if not summary:
            return jsonify({
                "success": False,
                "error": "æš‚æ— AIæ€»ç»“æ•°æ®ï¼Œè¯·å…ˆç”Ÿæˆæ€»ç»“"
            })

        return jsonify({
            "success": True,
            "data": summary
        })

    except Exception as e:
        print(f"âŒ è·å–AIæ€»ç»“é”™è¯¯: {e}")
        return jsonify({"success": False, "error": str(e)})




if __name__ == "__main__":
    if not os.path.exists("templates"):
        os.makedirs("templates")

    # æ•°æ®å·²åœ¨æ¨¡å—çº§åˆ«åˆå§‹åŒ–ï¼Œæ­¤å¤„æ— éœ€é‡å¤è°ƒç”¨

    print("ğŸŒ å¯åŠ¨Flaskåº”ç”¨...")
    print("ğŸ“± è®¿é—® http://127.0.0.1:5000 æŸ¥çœ‹ç½‘ç«™")
    print("ğŸ“° è®¿é—® http://127.0.0.1:5000/translated_news æŸ¥çœ‹å¤šæ¥æºç¿»è¯‘æ–°é—»")
    app.run(debug=True, host="127.0.0.1", port=5000)
