import sys
import os
import json
import time
import re
import random
import tempfile
import uuid
from datetime import datetime, timedelta
from urllib.parse import quote, urljoin

try:
    from selenium import webdriver
    from selenium.webdriver.common.by import By
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.chrome.service import Service
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.common.exceptions import TimeoutException, WebDriverException, NoSuchElementException
    from selenium.webdriver.common.action_chains import ActionChains
    from selenium.webdriver.common.keys import Keys
    
    class IrenaCrawler:
        def __init__(self):
            self.irena_url = "https://www.irena.org/News"
            self.driver = None
            self.content_data = []  # åˆå§‹åŒ–content_dataå±æ€§ï¼Œä¸å…¶ä»–çˆ¬è™«ä¿æŒä¸€è‡´
            self.search_keywords = [
                "solar energy",
                "photovoltaic",
                "solar power",
                "renewable energy"
            ]
            
        def _create_chrome_options(self):
            """åˆ›å»ºChromeé€‰é¡¹ï¼ˆæ¯æ¬¡è°ƒç”¨éƒ½ç”Ÿæˆæ–°çš„å”¯ä¸€ç›®å½•ï¼‰"""
            chrome_options = Options()

            # ä½¿ç”¨æ— å¤´æ¨¡å¼å‡å°‘èµ„æºå ç”¨å’Œå†²çª
            chrome_options.add_argument('--headless=new')
            chrome_options.add_argument('--disable-gpu')

            # ä¿®å¤ChromeDriveræƒé™é—®é¢˜
            chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
            chrome_options.add_experimental_option('useAutomationExtension', False)

            # åˆ›å»ºå”¯ä¸€çš„ç”¨æˆ·æ•°æ®ç›®å½•ï¼Œé¿å…å¤šå®ä¾‹å†²çª
            unique_dir = os.path.join(tempfile.gettempdir(), f"chrome_irena_{uuid.uuid4().hex}")
            chrome_options.add_argument(f'--user-data-dir={unique_dir}')

            # æ·»åŠ æ›´å¤šéš”ç¦»å‚æ•°
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-blink-features=AutomationControlled')
            chrome_options.add_argument(f'--remote-debugging-port={9222 + random.randint(0, 1000)}')
            chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
            chrome_options.add_argument('--window-size=1920,1080')

            return chrome_options

        def setup_driver(self):
            """è®¾ç½®æµè§ˆå™¨ç¯å¢ƒ"""
            try:
                # è‡ªåŠ¨æŸ¥æ‰¾ChromeDriver
                try:
                    self.driver = webdriver.Chrome(options=self._create_chrome_options())
                except Exception as e:
                    print(f"   æ–¹æ³•1å¤±è´¥: {e}")
                    # å°è¯•æŒ‡å®šChromeDriverè·¯å¾„ï¼ˆé‡æ–°ç”Ÿæˆoptionsé¿å…ç›®å½•å†²çªï¼‰
                    try:
                        possible_paths = [
                            "/usr/bin/chromedriver",
                            "/usr/local/bin/chromedriver",
                            "chromedriver"
                        ]

                        for path in possible_paths:
                            if os.path.exists(path):
                                service = Service(executable_path=path)
                                self.driver = webdriver.Chrome(service=service, options=self._create_chrome_options())
                                print(f"   âœ… ä½¿ç”¨ChromeDriverè·¯å¾„: {path}")
                                break
                        else:
                            self.driver = webdriver.Chrome(options=self._create_chrome_options())
                    except Exception as e2:
                        print(f"   æ–¹æ³•2å¤±è´¥: {e2}")
                        self.driver = webdriver.Chrome(options=self._create_chrome_options())
                
                self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
                return True
                
            except Exception as e:
                print(f"âŒ æµè§ˆå™¨å¯åŠ¨å¤±è´¥: {e}")
                print("ğŸ’¡ è¯·ç¡®ä¿å·²å®‰è£…Chromeæµè§ˆå™¨å’ŒChromeDriver")
                return False
        
        def close_driver(self):
            """å…³é—­æµè§ˆå™¨"""
            if self.driver:
                try:
                    self.driver.quit()
                except:
                    pass
                self.driver = None
        
        def perform_search_with_load_more(self, keyword, max_loads=5):
            """æ‰§è¡Œæœç´¢å¹¶ç‚¹å‡»Load moreåŠ è½½æ›´å¤šå†…å®¹"""
            all_news = []
            
            print(f"\nğŸ” æœç´¢å…³é”®è¯: '{keyword}' - è®¡åˆ’åŠ è½½ {max_loads} æ¬¡")
            
            try:
                # è®¿é—®æ–°é—»é¡µé¢
                self.driver.get(self.irena_url)
                time.sleep(3)
                
                # æ‰§è¡Œæœç´¢
                if self.find_and_use_search(keyword):
                    print(f"   âœ… æœç´¢ '{keyword}' æˆåŠŸ")
                    time.sleep(4)
                    
                    # çˆ¬å–å¤šè½®å†…å®¹
                    for load_count in range(max_loads):
                        current_load = load_count + 1
                        print(f"   ğŸ“„ ç¬¬ {current_load} è½®åŠ è½½...")
                        
                        # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡åŠ è½½ï¼Œç›´æ¥æå–å†…å®¹
                        # å¦‚æœæ˜¯åç»­åŠ è½½ï¼Œå…ˆç‚¹å‡»Load moreå†æå–
                        if load_count > 0:
                            if not self.click_load_more():
                                print(f"   â¹ï¸ æ— æ³•åŠ è½½æ›´å¤šå†…å®¹ï¼Œåœæ­¢åœ¨ç¬¬ {load_count} è½®")
                                break
                            # ç­‰å¾…æ–°å†…å®¹åŠ è½½
                            time.sleep(3)
                        
                        # æå–å½“å‰åŠ è½½çš„æ–°é—»
                        page_news = self.extract_detailed_news()
                        if page_news:
                            # å»é‡å¹¶æ·»åŠ 
                            new_count = 0
                            for news in page_news:
                                if not any(n['title'] == news['title'] for n in all_news):
                                    news['search_keyword'] = keyword
                                    news['load_round'] = current_load
                                    all_news.append(news)
                                    new_count += 1
                            print(f"   âœ… ç¬¬ {current_load} è½®æ‰¾åˆ° {new_count} æ¡æ–°æ–°é—»")
                        else:
                            print(f"   âš ï¸ ç¬¬ {current_load} è½®æœªæ‰¾åˆ°æ–°æ–°é—»")
                        
                        # æ˜¾ç¤ºå½“å‰è¿›åº¦
                        current_progress = self.get_current_progress()
                        if current_progress:
                            print(f"   ğŸ“Š å½“å‰è¿›åº¦: {current_progress}")
                    
                    print(f"   âœ… å·²å®Œæˆ {max_loads} è½®åŠ è½½")
                    
                else:
                    print(f"   âŒ æœç´¢ '{keyword}' å¤±è´¥")
                    
            except Exception as e:
                print(f"   âŒ æœç´¢ '{keyword}' è¿‡ç¨‹å‡ºé”™: {e}")
            
            return all_news
        
        def click_load_more(self):
            """ç‚¹å‡»Load moreæŒ‰é’®"""
            try:
                # å¤šç§Load moreæŒ‰é’®é€‰æ‹©å™¨
                load_more_selectors = [
                    "//button[contains(text(), 'Load more')]",
                    "//a[contains(text(), 'Load more')]",
                    "//div[contains(text(), 'Load more')]",
                    "//span[contains(text(), 'Load more')]",
                    "//*[contains(translate(., 'LOAD MORE', 'load more'), 'load more')]",
                    ".load-more",
                    "[class*='load-more']",
                    "button[class*='load']",
                    "a[class*='load']"
                ]
                
                for selector in load_more_selectors:
                    try:
                        if selector.startswith("//"):
                            elements = self.driver.find_elements(By.XPATH, selector)
                        else:
                            elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                        
                        for element in elements:
                            if element.is_displayed() and element.is_enabled():
                                print(f"   âœ… æ‰¾åˆ°Load moreæŒ‰é’®: {selector}")
                                # æ»šåŠ¨åˆ°å…ƒç´ ä½ç½®
                                self.driver.execute_script("arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});", element)
                                time.sleep(1)
                                # ç‚¹å‡»æŒ‰é’®
                                self.driver.execute_script("arguments[0].click();", element)
                                print("   âœ… å·²ç‚¹å‡»Load moreæŒ‰é’®")
                                return True
                    except Exception as e:
                        continue
                
                print("   âŒ æœªæ‰¾åˆ°Load moreæŒ‰é’®")
                return False
                
            except Exception as e:
                print(f"   âŒ ç‚¹å‡»Load moreå¤±è´¥: {e}")
                return False
        
        def get_current_progress(self):
            """è·å–å½“å‰åŠ è½½è¿›åº¦ï¼ˆå¦‚ï¼šYou've viewed 25 of 1905 resultsï¼‰"""
            try:
                # æŸ¥æ‰¾è¿›åº¦æ–‡æœ¬
                progress_selectors = [
                    "//*[contains(text(), 'You') and contains(text(), 'viewed') and contains(text(), 'of') and contains(text(), 'results')]",
                    "//*[contains(text(), 'viewed') and contains(text(), 'of')]",
                    ".search-results-count",
                    ".results-count",
                    "[class*='progress']",
                    "[class*='count']"
                ]
                
                for selector in progress_selectors:
                    try:
                        if selector.startswith("//"):
                            elements = self.driver.find_elements(By.XPATH, selector)
                        else:
                            elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                        
                        for element in elements:
                            text = element.text.strip()
                            if 'viewed' in text.lower() and 'of' in text.lower():
                                print(f"   ğŸ“ˆ åŠ è½½è¿›åº¦: {text}")
                                return text
                    except:
                        continue
                
                return None
                
            except:
                return None
        
        def find_and_use_search(self, keyword):
            """æŸ¥æ‰¾å¹¶ä½¿ç”¨æœç´¢åŠŸèƒ½"""
            try:
                # ç­‰å¾…é¡µé¢åŠ è½½
                time.sleep(3)
                
                # æ–¹æ³•1: æŸ¥æ‰¾æ˜æ˜¾çš„æœç´¢è¾“å…¥æ¡†
                search_input_selectors = [
                    "input[type='search']",
                    "input[name='search']",
                    "input[placeholder*='search' i]",
                    "input[placeholder*='Search' i]",
                    "#search",
                    ".search-input",
                    "input[type='text']"
                ]
                
                search_input = None
                for selector in search_input_selectors:
                    try:
                        elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                        for element in elements:
                            if element.is_displayed():
                                search_input = element
                                print(f"   âœ… æ‰¾åˆ°æœç´¢è¾“å…¥æ¡†: {selector}")
                                break
                        if search_input:
                            break
                    except:
                        continue
                
                if not search_input:
                    print("   âŒ æœªæ‰¾åˆ°æœç´¢è¾“å…¥æ¡†ï¼Œå°è¯•å…¶ä»–æ–¹æ³•...")
                    # æ–¹æ³•2: æŸ¥æ‰¾æ‰€æœ‰è¾“å…¥æ¡†
                    all_inputs = self.driver.find_elements(By.TAG_NAME, "input")
                    for input_elem in all_inputs:
                        try:
                            if input_elem.is_displayed() and input_elem.get_attribute('type') in ['text', 'search']:
                                placeholder = input_elem.get_attribute('placeholder') or ''
                                if 'search' in placeholder.lower():
                                    search_input = input_elem
                                    print("   âœ… é€šè¿‡placeholderæ‰¾åˆ°æœç´¢æ¡†")
                                    break
                        except:
                            continue
                
                if search_input:
                    # æ¸…é™¤å¹¶è¾“å…¥æœç´¢è¯
                    search_input.clear()
                    search_input.send_keys(keyword)
                    print(f"   âœ… å·²è¾“å…¥æœç´¢è¯: {keyword}")
                    time.sleep(1)
                    
                    # æŸ¥æ‰¾æœç´¢æŒ‰é’®
                    search_button_selectors = [
                        "button[type='submit']",
                        "input[type='submit']",
                        "button[class*='search']",
                        ".search-btn",
                        "button:contains('Search')",
                        "input[value*='Search' i]"
                    ]
                    
                    search_button = None
                    for selector in search_button_selectors:
                        try:
                            if selector == "button:contains('Search')":
                                # XPathæ–¹å¼æŸ¥æ‰¾åŒ…å«Searchæ–‡æœ¬çš„æŒ‰é’®
                                buttons = self.driver.find_elements(By.XPATH, "//button[contains(translate(., 'SEARCH', 'search'), 'search')]")
                            else:
                                buttons = self.driver.find_elements(By.CSS_SELECTOR, selector)
                            
                            for button in buttons:
                                if button.is_displayed():
                                    search_button = button
                                    print(f"   âœ… æ‰¾åˆ°æœç´¢æŒ‰é’®: {selector}")
                                    break
                            if search_button:
                                break
                        except:
                            continue
                    
                    # å¦‚æœæ²¡æ‰¾åˆ°æŒ‰é’®ï¼Œå°è¯•æŒ‰å›è½¦
                    if search_button:
                        self.driver.execute_script("arguments[0].click();", search_button)
                        print("   âœ… ç‚¹å‡»æœç´¢æŒ‰é’®")
                    else:
                        search_input.send_keys(Keys.ENTER)
                        print("   âœ… æŒ‰å›è½¦æ‰§è¡Œæœç´¢")
                    
                    time.sleep(4)
                    return True
                else:
                    print("   âŒ å®Œå…¨æ‰¾ä¸åˆ°æœç´¢æ¡†")
                    return False
                    
            except Exception as e:
                print(f"   âŒ æœç´¢è¿‡ç¨‹å‡ºé”™: {e}")
                return False
        
        def extract_detailed_news(self):
            """æå–è¯¦ç»†çš„æ–°é—»ä¿¡æ¯"""
            news_list = []
            
            try:
                # ç­‰å¾…é¡µé¢åŠ è½½
                time.sleep(2)
                
                # å¤šç§å¯èƒ½çš„é€‰æ‹©å™¨æ¥æŸ¥æ‰¾æ–°é—»é¡¹ç›®
                news_selectors = [
                    ".news-item",
                    ".article-item",
                    ".search-result",
                    ".result-item",
                    "div[class*='news']",
                    "div[class*='article']",
                    "li[class*='news']",
                    ".listing-item",
                    ".card",
                    ".news-card"
                ]
                
                news_elements = []
                for selector in news_selectors:
                    try:
                        elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                        if elements:
                            news_elements.extend(elements)
                    except:
                        continue
                
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç‰¹å®šç±»åçš„å…ƒç´ ï¼Œå°è¯•æŸ¥æ‰¾æ‰€æœ‰åŒ…å«é“¾æ¥çš„å—çº§å…ƒç´ 
                if not news_elements:
                    all_links = self.driver.find_elements(By.TAG_NAME, "a")
                    link_elements = set()
                    
                    for link in all_links:
                        try:
                            href = link.get_attribute('href')
                            text = link.text.strip()
                            if href and text and len(text) > 20 and 'irena.org' in href:
                                # è·å–é“¾æ¥çš„çˆ¶çº§æˆ–ç¥–å…ˆå…ƒç´ ä½œä¸ºæ–°é—»é¡¹
                                parent = link.find_element(By.XPATH, "./..")
                                link_elements.add(parent)
                        except:
                            continue
                    
                    news_elements = list(link_elements)
                
                print(f"   å½“å‰è½®æ¬¡æ‰¾åˆ° {len(news_elements)} ä¸ªå¯èƒ½çš„æ–°é—»å…ƒç´ ")
                
                for element in news_elements:
                    try:
                        news_item = self.extract_news_details(element)
                        if news_item and not any(n['title'] == news_item['title'] for n in news_list):
                            news_list.append(news_item)
                                
                    except Exception as e:
                        continue
                
                return news_list
                
            except Exception as e:
                print(f"   âŒ æå–æ–°é—»å¤±è´¥: {e}")
                return []
        
        def extract_news_details(self, element):
            """ä»å…ƒç´ ä¸­æå–è¯¦ç»†çš„æ–°é—»ä¿¡æ¯"""
            try:
                # åœ¨å…ƒç´ å†…æŸ¥æ‰¾é“¾æ¥
                links = element.find_elements(By.TAG_NAME, "a")
                for link in links:
                    title = link.text.strip()
                    href = link.get_attribute('href')
                    
                    if (title and len(title) > 20 and 
                        href and 'irena.org' in href and
                        self.is_solar_related(title)):
                        
                        # æå–è¯¦ç»†ä¿¡æ¯
                        date = self.extract_date_from_element(element)
                        summary = self.extract_summary_from_element(element)
                        category = self.extract_category_from_title(title)
                        
                        news_item = {
                            'title': title,
                            'link': href,
                            'date': date,
                            'summary': summary,
                            'category': category,
                            'source': 'IRENA',
                            'language': 'en',
                            'crawl_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        }
                        
                        return news_item
                return None
            except:
                return None
        
        def extract_date_from_element(self, element):
            """ä»å…ƒç´ ä¸­æå–æ—¥æœŸ"""
            try:
                element_text = element.text
                
                # æŸ¥æ‰¾æ—¥æœŸæ¨¡å¼
                date_patterns = [
                    r'\d{1,2}\s+\w+\s+\d{4}',
                    r'\d{4}-\d{2}-\d{2}',
                    r'\w+\s+\d{1,2},\s+\d{4}',
                    r'\d{1,2}/\d{1,2}/\d{4}'
                ]
                
                for pattern in date_patterns:
                    matches = re.findall(pattern, element_text)
                    if matches:
                        return matches[0]
            except:
                pass
            
            return datetime.now().strftime('%Y-%m-%d')
        
        def extract_summary_from_element(self, element):
            """ä»å…ƒç´ ä¸­æå–æ‘˜è¦"""
            try:
                element_text = element.text
                lines = element_text.split('\n')
                
                # æŸ¥æ‰¾å¯èƒ½çš„æ‘˜è¦è¡Œï¼ˆæ’é™¤æ ‡é¢˜å’Œæ—¥æœŸï¼‰
                for line in lines:
                    line = line.strip()
                    if (len(line) > 50 and len(line) < 300 and 
                        not re.search(r'\d{1,2}\s+\w+\s+\d{4}', line) and
                        not re.search(r'\d{4}-\d{2}-\d{2}', line) and
                        not line.startswith('http')):
                        return line
                
                return ""
                    
            except:
                return ""
        
        def extract_category_from_title(self, title):
            """ä»æ ‡é¢˜ä¸­æå–åˆ†ç±»"""
            try:
                title_lower = title.lower()
                
                if any(word in title_lower for word in ['report', 'study', 'analysis']):
                    return 'report'
                elif any(word in title_lower for word in ['news', 'press', 'announcement']):
                    return 'news'
                elif any(word in title_lower for word in ['event', 'conference', 'meeting', 'webinar']):
                    return 'event'
                elif any(word in title_lower for word in ['data', 'statistics', 'figures']):
                    return 'data'
                else:
                    return 'general'
            except:
                return 'general'
        
        def is_solar_related(self, title):
            """åˆ¤æ–­æ˜¯å¦ä¸å¤ªé˜³èƒ½ç›¸å…³"""
            if not title:
                return False
                
            title_lower = title.lower()
            solar_keywords = [
                'solar', 'photovoltaic', 'pv', 'renewable energy',
                'solar energy', 'solar power', 'solar panel', 'clean energy',
                'renewables', 'green energy', 'solar technology'
            ]
            
            return any(keyword in title_lower for keyword in solar_keywords)
        
        def crawl_with_load_more(self, loads_per_keyword=5):
            """ä½¿ç”¨Load moreçš„å…¨é¢çˆ¬å–"""
            if not self.driver and not self.setup_driver():
                return []
            
            all_news = []
            
            try:
                print("ğŸš€ å¼€å§‹ä½¿ç”¨Load moreåŠ è½½æ›´å¤šå†…å®¹çš„IRENAå…‰ä¼æ–°é—»çˆ¬å–...")
                
                # å¤šå…³é”®è¯æœç´¢ï¼Œæ¯ä¸ªå…³é”®è¯ç‚¹å‡»å¤šæ¬¡Load more
                for keyword in self.search_keywords:
                    keyword_news = self.perform_search_with_load_more(keyword, max_loads=loads_per_keyword)
                    if keyword_news:
                        all_news.extend(keyword_news)
                        print(f"âœ… å…³é”®è¯ '{keyword}' å…±æ‰¾åˆ° {len(keyword_news)} æ¡æ–°é—»")
                    
                    # éšæœºå»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡å¿«
                    time.sleep(random.uniform(2, 4))
                
                # å»é‡
                unique_news = []
                seen_titles = set()
                for news in all_news:
                    if news['title'] not in seen_titles:
                        unique_news.append(news)
                        seen_titles.add(news['title'])
                
                print(f"\nğŸ¯ å»é‡åæ€»å…±æ‰¾åˆ° {len(unique_news)} æ¡å”¯ä¸€æ–°é—»")
                
                return unique_news
                
            except Exception as e:
                print(f"âŒ çˆ¬å–è¿‡ç¨‹å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
                return []
        
        def save_news_data(self, news_list, filename='irena_news_load_more.json'):
            """ä¿å­˜æ–°é—»æ•°æ®"""
            try:
                # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
                output_data = {
                    'crawl_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'total_load_rounds': len(set(n.get('load_round', 1) for n in news_list)),
                    'total_news': len(news_list),
                    'news_list': news_list
                }
                
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(output_data, f, ensure_ascii=False, indent=2)
                print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ° {filename}")
                return True
            except Exception as e:
                print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
                return False
        
        def create_sample_data(self):
            """åˆ›å»ºç¤ºä¾‹æ•°æ®"""
            sample_news = [
                {
                    'title': 'IRENA Report: Solar Energy Leads Global Renewable Growth',
                    'link': 'https://www.irena.org/news/articles/2024/solar-energy-growth',
                    'date': '2024-09-15',
                    'summary': 'New report shows solar energy continuing to lead global renewable energy capacity growth.',
                    'source': 'IRENA',
                    'language': 'en',
                    'search_keyword': 'solar energy',
                    'load_round': 1
                }
            ]
            return sample_news
    
    # ç‹¬ç«‹è¿è¡Œæµ‹è¯•
    def main():
        crawler = IrenaCrawler()
        
        try:
            print("=" * 60)
            print("ğŸš€ IRENAå…‰ä¼æ–°é—»Load Moreçˆ¬å–å¼€å§‹")
            print("=" * 60)
            
            # è®¾ç½®åŠ è½½æ¬¡æ•°
            loads_to_perform = 5  # å¯ä»¥è°ƒæ•´è¿™ä¸ªæ•°å­—æ¥åŠ è½½æ›´å¤šå†…å®¹
            
            news_data = crawler.crawl_with_load_more(loads_per_keyword=loads_to_perform)
            
            if news_data:
                print(f"\nğŸ‰ çˆ¬å–å®Œæˆï¼æ€»å…±æ‰¾åˆ° {len(news_data)} æ¡å…‰ä¼æ–°é—»")
                
                # ä¿å­˜æ•°æ®
                crawler.save_news_data(news_data)
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                load_rounds = set()
                keywords_used = set()
                
                for news in news_data:
                    load_rounds.add(news.get('load_round', 1))
                    keywords_used.add(news.get('search_keyword', 'unknown'))
                
                print(f"\nğŸ“Š çˆ¬å–ç»Ÿè®¡:")
                print(f"   åŠ è½½è½®æ¬¡: {len(load_rounds)} è½®")
                print(f"   ä½¿ç”¨å…³é”®è¯: {', '.join(keywords_used)}")
                print(f"   æ€»æ–°é—»æ•°: {len(news_data)} æ¡")
                
                print(f"\nğŸ“° æ–°é—»åˆ—è¡¨ (æ˜¾ç¤ºå‰20æ¡):")
                for i, news in enumerate(news_data[:20], 1):
                    print(f"{i:2d}. [ç¬¬{news.get('load_round', 1)}è½®] [{news['date']}] {news['title']}")
                    if news.get('summary'):
                        print(f"    æ‘˜è¦: {news['summary']}")
                    print()
                
            else:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°æ–°é—»æ•°æ®ï¼Œåˆ›å»ºç¤ºä¾‹æ•°æ®...")
                sample_data = crawler.create_sample_data()
                crawler.save_news_data(sample_data)
                print("âœ… ç¤ºä¾‹æ•°æ®å·²åˆ›å»º")
                
            return news_data
            
        finally:
            crawler.close_driver()
            print("\nâœ… ç¨‹åºæ‰§è¡Œå®Œæˆ")
    
    if __name__ == "__main__":
        main()
        
except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·å®‰è£…Selenium: pip install selenium")