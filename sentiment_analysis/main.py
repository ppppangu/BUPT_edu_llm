#!/usr/bin/env python3
"""
è‚¡ç¥¨å¸‚åœºæƒ…ç»ªåˆ†æç³»ç»Ÿ - å®Œæ•´ç‰ˆä¸»ç¨‹åº
è¿è¡Œ: python main.py --mode full
"""

import os
import sys
import logging
import argparse
import traceback
import json
from datetime import datetime, timedelta
from crawler import StockCrawler
from processor import DataProcessor
from calculator import SentimentCalculator
from visualizer import SentimentVisualizer
from test_data import EnhancedTestDataGenerator

class StockSentimentSystem:
    def __init__(self):
        self.setup_logging()
        self.setup_directories()
        
        # åˆå§‹åŒ–å„ä¸ªæ¨¡å—
        self.crawler = StockCrawler()
        self.processor = DataProcessor()
        self.calculator = SentimentCalculator()
        self.visualizer = SentimentVisualizer()
        self.test_generator = EnhancedTestDataGenerator()
        
        self.logger = logging.getLogger('StockSentimentSystem')
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        os.makedirs('logs', exist_ok=True)
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('logs/system.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
    
    def setup_directories(self):
        """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
        directories = [
            'data/raw',
            'data/processed', 
            'data/results',
            'data/reports',
            'data/charts',
            'data/wordcloud',
            'config',
            'logs'
        ]
        
        for directory in directories:
            os.makedirs(directory, exist_ok=True)
    
    def run_data_collection(self):
        """è¿è¡Œæ•°æ®é‡‡é›†"""
        try:
            self.logger.info("æ‰§è¡Œæ•°æ®é‡‡é›†...")
            results = self.crawler.run_all_crawlers()
            self.logger.info("æ•°æ®é‡‡é›†å®Œæˆ")
            return True
        except Exception as e:
            self.logger.error(f"æ•°æ®é‡‡é›†å¤±è´¥: {e}")
            return False
    
    def run_data_processing(self, date_str=None):
        """è¿è¡Œæ•°æ®å¤„ç†"""
        try:
            if date_str is None:
                date_str = datetime.now().strftime('%Y%m%d')
                
            self.logger.info(f"å¤„ç† {date_str} çš„æ•°æ®...")
            df = self.processor.process_daily_data(date_str)
            
            if df.empty:
                self.logger.warning(f"æ²¡æœ‰å¤„ç†åçš„æ•°æ®: {date_str}")
                return False
                
            self.logger.info(f"æ•°æ®å¤„ç†å®Œæˆ: {len(df)} æ¡è®°å½•")
            return True
        except Exception as e:
            self.logger.error(f"æ•°æ®å¤„ç†å¤±è´¥: {e}")
            return False
    
    def run_sentiment_calculation(self, date_str=None):
        """è¿è¡Œæƒ…ç»ªè®¡ç®—"""
        try:
            if date_str is None:
                date_str = datetime.now().strftime('%Y%m%d')
                
            self.logger.info(f"è®¡ç®— {date_str} çš„æƒ…ç»ªæŒ‡æ•°...")
            report = self.calculator.generate_daily_sentiment_report(date_str)
            
            if not report:
                self.logger.warning(f"æƒ…ç»ªè®¡ç®—è¿”å›ç©ºç»“æœ: {date_str}")
                return False
                
            self.logger.info("æƒ…ç»ªè®¡ç®—å®Œæˆ")
            return True
        except Exception as e:
            self.logger.error(f"æƒ…ç»ªè®¡ç®—å¤±è´¥: {e}")
            return False
    
    def run_visualization(self, date_str=None):
        """è¿è¡Œå¯è§†åŒ–"""
        try:
            if date_str is None:
                date_str = datetime.now().strftime('%Y%m%d')
                
            self.logger.info(f"ç”Ÿæˆ {date_str} çš„å¯è§†åŒ–å›¾è¡¨...")
            self.visualizer.create_daily_sentiment_dashboard(date_str)
            self.visualizer.create_word_cloud(date_str)
            self.logger.info("å¯è§†åŒ–ç”Ÿæˆå®Œæˆ")
            return True
        except Exception as e:
            self.logger.error(f"å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")
            return False
    
    def run_historical_analysis(self, days=7):
        """è¿è¡Œå†å²åˆ†æ"""
        try:
            self.logger.info(f"ç”Ÿæˆ {days} å¤©å†å²åˆ†æ...")
            self.calculator.generate_historical_analysis(days=days)
            self.visualizer.create_historical_trend_chart(days=days)
            self.logger.info("å†å²åˆ†æå®Œæˆ")
            return True
        except Exception as e:
            self.logger.error(f"å†å²åˆ†æå¤±è´¥: {e}")
            return False
    
    def run_daily_analysis(self, date_str=None):
        """è¿è¡Œå•æ—¥åˆ†æ"""
        if date_str is None:
            date_str = datetime.now().strftime('%Y%m%d')
        
        success = True
        
        # æ•°æ®å¤„ç†
        if not self.run_data_processing(date_str):
            success = False
        
        # æƒ…ç»ªè®¡ç®—
        if not self.run_sentiment_calculation(date_str):
            success = False
        
        # å¯è§†åŒ–
        if not self.run_visualization(date_str):
            success = False
        
        return success
    
    def run_batch_analysis(self, days=7):
        """è¿è¡Œæ‰¹é‡åˆ†æ - å¤„ç†å¤šå¤©æ•°æ®"""
        self.logger.info(f"å¼€å§‹æ‰¹é‡å¤„ç† {days} å¤©çš„æ•°æ®...")
        
        processed_dates = []
        
        # å¤„ç†æ¯ä¸€å¤©çš„æ•°æ®
        for i in range(days):
            date_offset = -i  # ä»ä»Šå¤©å¾€å‰æ¨
            target_date = datetime.now() + timedelta(days=date_offset)
            date_str = target_date.strftime('%Y%m%d')
            
            self.logger.info(f"å¤„ç†æ—¥æœŸ: {date_str}")
            
            # æ£€æŸ¥åŸå§‹æ•°æ®æ˜¯å¦å­˜åœ¨
            raw_files_exist = any(
                os.path.exists(f"data/raw/{source}_{date_str}.json") 
                for source in ['eastmoney', 'xueqiu', 'weibo', 'tieba']
            )
            
            if not raw_files_exist:
                self.logger.warning(f"è·³è¿‡ {date_str} - æ²¡æœ‰åŸå§‹æ•°æ®")
                continue
            
            # è¿è¡Œå•æ—¥åˆ†æ
            if self.run_daily_analysis(date_str):
                processed_dates.append(date_str)
        
        # ç”Ÿæˆå†å²åˆ†æ
        if processed_dates:
            self.logger.info(f"æˆåŠŸå¤„ç† {len(processed_dates)} å¤©çš„æ•°æ®ï¼Œç”Ÿæˆå†å²åˆ†æ...")
            self.run_historical_analysis(days=days)
            
            # æ‰“å°å¤„ç†ç»“æœ
            print(f"\nâœ… æ‰¹é‡å¤„ç†å®Œæˆ!")
            print(f"å¤„ç†äº† {len(processed_dates)} å¤©çš„æ•°æ®:")
            for date in sorted(processed_dates):
                readable_date = f"{date[:4]}-{date[4:6]}-{date[6:8]}"
                print(f"  ğŸ“… {readable_date}")
            
            return True
        else:
            self.logger.error("æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•æ•°æ®")
            return False
    
    def run_full_analysis(self, date_str=None, include_history=True):
        """è¿è¡Œå®Œæ•´åˆ†ææµç¨‹"""
        if date_str is None:
            date_str = datetime.now().strftime('%Y%m%d')
        
        self.logger.info(f"å¼€å§‹æ‰§è¡Œå®Œæ•´çš„è‚¡ç¥¨æƒ…ç»ªåˆ†ææµç¨‹ - {date_str}")
        
        success_steps = 0
        total_steps = 3  # é‡‡é›† + åˆ†æ + å¯è§†åŒ–
        
        try:
            # 1. æ•°æ®é‡‡é›†
            self.logger.info("æ­¥éª¤ 1/3: æ•°æ®é‡‡é›†")
            if self.run_data_collection():
                success_steps += 1
            else:
                self.logger.warning("æ•°æ®é‡‡é›†å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ç°æœ‰æ•°æ®ç»§ç»­...")
            
            # 2. å•æ—¥åˆ†æ
            self.logger.info("æ­¥éª¤ 2/3: æ•°æ®åˆ†æ")
            if self.run_daily_analysis(date_str):
                success_steps += 1
            else:
                self.logger.error("æ•°æ®åˆ†æå¤±è´¥")
                return False
            
            # 3. å†å²åˆ†æï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if include_history:
                self.logger.info("æ­¥éª¤ 3/3: å†å²åˆ†æ")
                if self.run_historical_analysis(days=7):
                    success_steps += 1
                else:
                    self.logger.warning("å†å²åˆ†æå¤±è´¥ï¼Œä½†å•æ—¥åˆ†æå®Œæˆ")
            
            self.logger.info(f"å®Œæ•´çš„åˆ†ææµç¨‹æ‰§è¡Œå®Œæˆï¼æˆåŠŸæ­¥éª¤: {success_steps}/{total_steps}")
            
            # æ‰“å°ç®€è¦æŠ¥å‘Š
            self.print_daily_report(date_str)
            
            return success_steps >= 2  # åªè¦ä¸»è¦æ­¥éª¤æˆåŠŸå°±è®¤ä¸ºæˆåŠŸ
            
        except Exception as e:
            self.logger.error(f"åˆ†ææµç¨‹æ‰§è¡Œå¤±è´¥: {e}")
            traceback.print_exc()
            return False
    
    def generate_test_data(self, days=7):
        """ç”Ÿæˆæµ‹è¯•æ•°æ®"""
        try:
            self.logger.info(f"ç”Ÿæˆ {days} å¤©çš„æµ‹è¯•æ•°æ®")
            self.test_generator.create_sample_sentiment_words()
            self.test_generator.generate_weekly_data(days=days, posts_per_source=25)
            self.logger.info("æµ‹è¯•æ•°æ®ç”Ÿæˆå®Œæˆ")
            return True
        except Exception as e:
            self.logger.error(f"æµ‹è¯•æ•°æ®ç”Ÿæˆå¤±è´¥: {e}")
            return False
    
    def print_daily_report(self, date_str=None):
        """æ‰“å°å½“æ—¥æŠ¥å‘Š"""
        if date_str is None:
            date_str = datetime.now().strftime('%Y%m%d')
        
        report_file = f"data/results/sentiment_report_{date_str}.json"
        
        if not os.path.exists(report_file):
            self.logger.warning(f"æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨: {report_file}")
            return
        
        try:
            with open(report_file, 'r', encoding='utf-8') as f:
                report_data = json.load(f)
            
            print("\n" + "="*60)
            print("           è‚¡ç¥¨å¸‚åœºæƒ…ç»ªåˆ†ææŠ¥å‘Š")
            print("="*60)
            print(f"åˆ†ææ—¥æœŸ: {report_data['date']}")
            print(f"æƒ…ç»ªæŒ‡æ•°: {report_data['normalized_sentiment_index']:.2f}")
            print(f"å¸‚åœºçŠ¶æ€: {report_data['market_state']}")
            print(f"æ•°æ®ç½®ä¿¡åº¦: {report_data['confidence_score']:.1%}")
            print(f"åˆ†æå¸–å­æ•°: {report_data['total_posts']}")
            
            print(f"\næƒ…ç»ªåˆ†å¸ƒ:")
            for sentiment, count in report_data['sentiment_distribution'].items():
                percentage = (count / report_data['total_posts']) * 100
                print(f"  {sentiment}: {count} æ¡ ({percentage:.1f}%)")
            
            print(f"\nå„æ¥æºæƒ…ç»ªæŒ‡æ•°:")
            for source, stats in report_data['source_statistics'].items():
                print(f"  {source}: {stats['normalized_index']:.2f}")
            
            print(f"\næŠ•èµ„å»ºè®®:")
            rec = report_data['recommendation']
            print(f"  å¸‚åœºå±•æœ›: {rec['outlook']}")
            print(f"  å»ºè®®æ“ä½œ: {rec['action']}")
            print(f"  é£é™©ç­‰çº§: {rec['risk_level']}")
            print("="*60)
            
        except Exception as e:
            self.logger.error(f"æ‰“å°æŠ¥å‘Šå¤±è´¥: {e}")
    
    def check_system_status(self):
        """æ£€æŸ¥ç³»ç»ŸçŠ¶æ€"""
        current_date = datetime.now().strftime('%Y%m%d')
        
        print("\n" + "="*60)
        print("ç³»ç»ŸçŠ¶æ€æ£€æŸ¥")
        print("="*60)
        
        # æ£€æŸ¥ç›®å½•
        directories = ['data/raw', 'data/processed', 'data/results', 'data/charts']
        for directory in directories:
            if os.path.exists(directory):
                file_count = len([f for f in os.listdir(directory) if f.endswith('.json') or f.endswith('.png')])
                print(f"ğŸ“ {directory}: {file_count} ä¸ªæ–‡ä»¶")
            else:
                print(f"âŒ {directory}: ç›®å½•ä¸å­˜åœ¨")
        
        # æ£€æŸ¥å…³é”®æ–‡ä»¶
        key_files = [
            f'data/raw/eastmoney_{current_date}.json',
            f'data/processed/processed_{current_date}.json',
            f'data/results/sentiment_report_{current_date}.json',
            f'data/charts/sentiment_dashboard_{current_date}.png',
            'data/reports/historical_analysis_7days.json',
            'data/charts/historical_trend_7days.png'
        ]
        
        print(f"\nå…³é”®æ–‡ä»¶æ£€æŸ¥:")
        for file_path in key_files:
            if os.path.exists(file_path):
                file_size = os.path.getsize(file_path)
                print(f"âœ… {file_path} - {file_size} å­—èŠ‚")
            else:
                print(f"âŒ {file_path} - æ–‡ä»¶ä¸å­˜åœ¨")
        
        print("="*60)

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='è‚¡ç¥¨å¸‚åœºæƒ…ç»ªåˆ†æç³»ç»Ÿ')
    parser.add_argument('--mode', 
                       choices=['full', 'collect', 'analyze', 'visualize', 'test', 'batch', 'status'], 
                       default='full', 
                       help='è¿è¡Œæ¨¡å¼: full(å®Œæ•´æµç¨‹), collect(ä»…é‡‡é›†), analyze(ä»…åˆ†æ), visualize(ä»…å¯è§†åŒ–), test(ç”Ÿæˆæµ‹è¯•æ•°æ®), batch(æ‰¹é‡å¤„ç†), status(ç³»ç»ŸçŠ¶æ€)')
    parser.add_argument('--date', help='æŒ‡å®šåˆ†ææ—¥æœŸ (æ ¼å¼: YYYYMMDD)')
    parser.add_argument('--days', type=int, default=7, help='å¤„ç†å¤©æ•° (ç”¨äºtestå’Œbatchæ¨¡å¼)')
    parser.add_argument('--no-history', action='store_true', help='ä¸åŒ…å«å†å²åˆ†æ')
    
    args = parser.parse_args()
    
    system = StockSentimentSystem()
    
    print("è‚¡ç¥¨å¸‚åœºæƒ…ç»ªåˆ†æç³»ç»Ÿ - å®Œæ•´ç‰ˆ")
    print("=" * 50)
    
    success = False
    
    try:
        if args.mode == 'full':
            # å®Œæ•´æµç¨‹
            success = system.run_full_analysis(args.date, not args.no_history)
            
        elif args.mode == 'collect':
            # ä»…æ•°æ®é‡‡é›†
            success = system.run_data_collection()
            
        elif args.mode == 'analyze':
            # ä»…åˆ†æï¼ˆä½¿ç”¨ç°æœ‰æ•°æ®ï¼‰
            if args.date:
                success = system.run_daily_analysis(args.date)
            else:
                success = system.run_daily_analysis()
            
        elif args.mode == 'visualize':
            # ä»…å¯è§†åŒ–
            if args.date:
                success = system.run_visualization(args.date)
            else:
                success = system.run_visualization()
            
        elif args.mode == 'test':
            # ç”Ÿæˆæµ‹è¯•æ•°æ®
            success = system.generate_test_data(args.days)
            if success:
                print(f"\nâœ… {args.days}å¤©æµ‹è¯•æ•°æ®ç”Ÿæˆå®Œæˆï¼")
                print("ç°åœ¨å¯ä»¥è¿è¡Œåˆ†æ: python main.py --mode batch --days 7")
            
        elif args.mode == 'batch':
            # æ‰¹é‡å¤„ç†
            success = system.run_batch_analysis(args.days)
            
        elif args.mode == 'status':
            # ç³»ç»ŸçŠ¶æ€
            system.check_system_status()
            success = True
    
    except Exception as e:
        print(f"ç³»ç»Ÿè¿è¡Œå‡ºé”™: {e}")
        traceback.print_exc()
        success = False
    
    print("\n" + "=" * 50)
    if success:
        print("âœ… ç³»ç»Ÿè¿è¡ŒæˆåŠŸï¼")
        print("ğŸ“Š æŸ¥çœ‹ç»“æœ:")
        print("   - åŸå§‹æ•°æ®: data/raw/")
        print("   - å¤„ç†æ•°æ®: data/processed/")
        print("   - åˆ†ææŠ¥å‘Š: data/results/") 
        print("   - å¯è§†åŒ–å›¾è¡¨: data/charts/")
        print("   - å†å²åˆ†æ: data/reports/")
    else:
        print("âŒ ç³»ç»Ÿè¿è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")
    print("=" * 50)

if __name__ == "__main__":
    main()